{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_7zFgpvU6ef"
      },
      "source": [
        "Creating a consolidated dataset of reddit posts. These reddit posts are classified either depressed or not depressed. ~30,000 samples of both classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCf89tWDaYQz",
        "outputId": "d3a5aca0-b1c8-41b3-b5c5-06df6e82b5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OHxKd0Lsf0Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/303_TRANSCRIPT.csv',sep = '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D4weTDkWwEH_",
        "outputId": "54572ef8-d9e2-49ec-c837-f00f6a625c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   start_time  stop_time      speaker  \\\n",
              "0      26.276     48.696        Ellie   \n",
              "1      49.256     50.406        Ellie   \n",
              "2      50.686     51.836  Participant   \n",
              "3      52.576     54.136        Ellie   \n",
              "4      54.816     56.236        Ellie   \n",
              "\n",
              "                                               value  \n",
              "0  hi i'm ellie thanks for coming in today i was ...  \n",
              "1                            how are you doing today  \n",
              "2                            okay how 'bout yourself  \n",
              "3                                   i'm great thanks  \n",
              "4                      where are you from originally  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2c78f3b-3d0a-4509-910c-23a898acad69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>stop_time</th>\n",
              "      <th>speaker</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.276</td>\n",
              "      <td>48.696</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>hi i'm ellie thanks for coming in today i was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49.256</td>\n",
              "      <td>50.406</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>how are you doing today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50.686</td>\n",
              "      <td>51.836</td>\n",
              "      <td>Participant</td>\n",
              "      <td>okay how 'bout yourself</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52.576</td>\n",
              "      <td>54.136</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>i'm great thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54.816</td>\n",
              "      <td>56.236</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>where are you from originally</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2c78f3b-3d0a-4509-910c-23a898acad69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2c78f3b-3d0a-4509-910c-23a898acad69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2c78f3b-3d0a-4509-910c-23a898acad69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0496d3a0-c05a-402a-9e46-e722e96cddef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0496d3a0-c05a-402a-9e46-e722e96cddef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0496d3a0-c05a-402a-9e46-e722e96cddef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 191,\n  \"fields\": [\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290.24906494356145,\n        \"min\": 26.276,\n        \"max\": 959.486,\n        \"num_unique_values\": 191,\n        \"samples\": [\n          836.886,\n          419.696,\n          856.746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 289.6094362577544,\n        \"min\": 48.696,\n        \"max\": 960.376,\n        \"num_unique_values\": 191,\n        \"samples\": [\n          838.536,\n          422.736,\n          857.206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Participant\",\n          \"Ellie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 156,\n        \"samples\": [\n          \"and uh we got into an argument because you know how your kids sometimes don't wanna hear it you know\",\n          \"what's memorable for me is that i'm the only one in my family with a degree so it's kinda like yeah it's kinda even though i'm the baby of ten kids you know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/train_split_Depression_AVEC2017.csv')"
      ],
      "metadata": {
        "id": "bwMA-mUdwFKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Ag7LFH-hw0uP",
        "outputId": "67f9f2a8-3d3e-42a9-b0b5-06f7d98deb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Participant_ID  PHQ8_Binary  PHQ8_Score  Gender  PHQ8_NoInterest  \\\n",
              "0             303            0           0       0                0   \n",
              "1             304            0           6       0                0   \n",
              "2             305            0           7       1                0   \n",
              "3             310            0           4       1                1   \n",
              "4             312            0           2       1                0   \n",
              "\n",
              "   PHQ8_Depressed  PHQ8_Sleep  PHQ8_Tired  PHQ8_Appetite  PHQ8_Failure  \\\n",
              "0               0         0.0           0              0             0   \n",
              "1               1         1.0           2              2             0   \n",
              "2               1         1.0           2              2             1   \n",
              "3               1         0.0           0              0             1   \n",
              "4               0         1.0           1              0             0   \n",
              "\n",
              "   PHQ8_Concentrating  PHQ8_Moving  \n",
              "0                   0            0  \n",
              "1                   0            0  \n",
              "2                   0            0  \n",
              "3                   1            0  \n",
              "4                   0            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c67972c-70e6-4164-86cf-82163b4931ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>PHQ8_Binary</th>\n",
              "      <th>PHQ8_Score</th>\n",
              "      <th>Gender</th>\n",
              "      <th>PHQ8_NoInterest</th>\n",
              "      <th>PHQ8_Depressed</th>\n",
              "      <th>PHQ8_Sleep</th>\n",
              "      <th>PHQ8_Tired</th>\n",
              "      <th>PHQ8_Appetite</th>\n",
              "      <th>PHQ8_Failure</th>\n",
              "      <th>PHQ8_Concentrating</th>\n",
              "      <th>PHQ8_Moving</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>304</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>305</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>310</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>312</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c67972c-70e6-4164-86cf-82163b4931ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c67972c-70e6-4164-86cf-82163b4931ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c67972c-70e6-4164-86cf-82163b4931ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3a9baa6-a9bb-49fb-a282-6533a5dd1088\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3a9baa6-a9bb-49fb-a282-6533a5dd1088')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3a9baa6-a9bb-49fb-a282-6533a5dd1088 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"Participant_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55,\n        \"min\": 303,\n        \"max\": 491,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          430,\n          319,\n          312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Binary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_NoInterest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Depressed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Sleep\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0045717597489865,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Tired\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Appetite\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Failure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Concentrating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ8_Moving\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['PHQ8_Binary'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "E_WPK401CXWq",
        "outputId": "8ef190ee-83c5-4579-8f86-dd3aed1b3202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PHQ8_Binary\n",
              "0    77\n",
              "1    30\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHQ8_Binary</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preset_speaker = \"Participant\"\n",
        "filtered_rows = df[df['speaker'] == preset_speaker]\n",
        "concatenated_text = ' '.join(filtered_rows['value'].astype(str))\n",
        "print(concatenated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ciQ_IDMw2Ca",
        "outputId": "19225b2f-f097-44e1-dee2-083e7b73e92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okay how 'bout yourself here in california yeah oh well that it's big and broad there's a lot to do a lot of um um job opportunities than other states um pretty much that it's big and there's a lot you can do here traffic um maybe the violence rate bad news even though you know you wanna know what's going on in your environment but you still have to watch it so you can you know look out to see what's going on on a daily basis sociology i have a um two year degree in liberal arts but my major was sociology no i'm actually an m_t_a bus operator well since metro is steady growing um my dream job is to move up in the company and i'm about to actually start some classes for supervisory next week so um 'cause they look to promote within the company so that's the good thing there's a lot of opportunities at metro where you can take classes and they'll pay for your tuition and things of that nature thanks well it's not actually hard as right now it's easy if you take advantage of it right now 'cause they look to promote within so you know so since i'm already working there that's a good thing so it's good to go ahead and take the classes that you need that you're interested in and go ahead and move up the ladder as soon as possible  what do you mean i'm sorry okay read take a long walk hot bath meditate just close my eyes sometimes i'm pretty much good because see by me being a bus operator you run into circumstances and situations you gotta remain calm and still remain professional at the same time well i look at it like it it goes with i mean it comes with experience you know um you do something on a continuous basis usually you some somewhere down the line you become good at it you know so i i look at it like that so i've been driving for years and dealing with the public so it's just how you handle circumstances you you know treat people like you wanna be treated no i'm pretty good at it now maybe when i was younger you know you as you get older you get wiser you learn different things and i'm still learning today i would say my family you know my kids you know even though you know i had been having a lot of deaths around me but that's just go that's part of the life experience you know you born here but you gotta leave here one day but my kids will keep me you know sane and you know i love them and my family   thank you no <laughter> um setting good examples you know because you're the first teacher you know and you wanna set a positive good example for your kids and i think that's a good thing and it starts at home well um by you being the first teacher your kids you're you're their one that they see on a daily basis when they wake up so whatever's been taught in the home they lookin' and learning every day you know whether it's a home school you know people kids have a tendency to do things what they see you know what i mean  so you try to keep it positive teach 'em good morals and values and how to get along with other people regardless of race and you know different things of that nature i have a um four and a half year old son i have a seven year old daughter and i also have a twenty three year old yeah i'm 'bout to be well my daughter's pregnant with a boy she has three um little girls so i have three grandkids and um one on the way which is a boy this time yeah thank you the hardest thing is well right now i'm a single parent so that makes it hard alone itself you know and they can be expensive at times you know it depends on the person's situation you know the whether they have help or a job you know things of that nature to help the situation better but it's hard you know but you i try to you know keep a job keep food in the house you know just maintain and support my kids the best way i can with my kids or just period what's memorable for me is that i'm the only one in my family with a degree so it's kinda like yeah it's kinda even though i'm the baby of ten kids you know and i've always kept that in the back of my mind even though everybody well pretty much my whole family have decent job but i'm the only one with a degree so i kinda like gave myself a pat on the back like you know you know i just that's the only thing i remember graduating you know and my family there and to support me  thank you happy that i accomplished something you know just even though it may not be much but it was better than just have having a high school diploma and i had um i was working on my bachelor's degree but i ended up in a bad car accident i never went back i got distracted and you know i was working at the same time but i was just like moreso i needed income than than um schooling at that time because i was a young parent you know 'cause i had my daughter at seventeen so i was like i needed the money to support her but i never went back but i feel like it's never too late so i feel like i'll take some classes now that i'm with metro to help me move up the ladder so  that's why i'm starting a class next week thank you hm well the advice i would've gave myself that i probably wouldn't have been a young mother at a young age and that i probably would've stayed in school you know not let the accident just distract me and not i would've remained in school i probably wouldn't have had kids early you know um rather i probably would've stayed in school and probably have a part time job or something just i just feel like um education is a excellent thing for a person just having knowledge and learning different things keeping your mind open to learning new ideas every day so i think that's a plus you know in anybody's shoes just to better they selves you know through education maybe to um maybe promote within your company or whatever the case may be that they help better your career i'm not quite sure um you learn from your mistakes you know but at the same time you don't continue to make the same ones i feel like it's okay to make a mistake but long as you do something to change you know um like myself even though i'm going to school late but still i'm going you know i wanna better myself career wise so  yes my oldest daughter we had a argument because just the life that she's living right now and the things that she's going through and um i had told her that she just needed to make some changes to better her situation and uh we got into an argument because you know how your kids sometimes don't wanna hear it you know hear the stuff that you're saying even though it's true or  or they just you know well they just don't wanna hear it you know they may be going through something they don't wanna hear but we got into a argument about it but that just happened you know i just told her i'm not i'm sorry very close very close it's just that the the situation my daughter's in she just needs to make some changes to better her her life and I'll be telling she's um she's kinda like stubborn in her own way you know i was raised to listen to your mom you know your mom's not gonna tell you nothing wrong and i've been telling her over the years you know different things and it's it's kinda like i was talking to a wall because she she did the opposite and now she's she regretting it you know 'cause she's like my mom told me this you know mom i'm doing the opposite so i guess she gotta bump her head a couple of times to get it it's kinda like i done told you i done left it alone and now it's up to you to make the change it's very frustrating because it's like i'm talking to a wall and she's not hearing me and i'm like it seem like it's taking forever for her to change but it's left up to the individual whenever they're ready you know what i mean once the person get tired of something they'll make it change it may not be when you want it to happen but the ball is her court you know i only can do so much oh wow i have my days um since i have two little ones um i kinda like trained them to go to bed at eight o clock because you know they gotta go to school and i think it's important to have a good night's rest because it kinda like <clears throat> it it kinda like gets you ready for the next day or you know how you gonna feel if you rested what type of person you'll be that day you know 'cause everybody have they days whether they're good or bad but that's just a part of life and i feel like if you had a good night's good good night's rest hopefully you'll have a good day you know pretty much you know i need my rest because i'm out there driving that bus and dealing with all these people and you know  the job itself if very stressful so i feel like if i'm rested it'll help me what am i like irritated tired um lazy you know feel like i wanna lay down probably go to sleep <laughter> get the rest that i need but <laughter> i never thought about that i just you know 'cause like i said you know everybody have their moments they do i never thought about that hm no no i don't really have a best friend but a person that i deal with and i used to work with um she would probably tell you that i'm very um outgoing a go getter dependable responsible i'm a um people person i get along with others you know i'm kinda like um i leave a good a a good mark whether i know you or not if you was to you know like  like you and i now you know i um you'd probably say oh she seems like a nice young lady or whatever you know something like that thank you well i try to stay happy i'd rather be happy than sad my kids keep me going you know what i mean especially when i go to pick them up from school or their being hey mom you know that just kinda make my day just them run up to me you know and be happy and excited you know what i mean  thank you you're more than welcome you have a good day goodbye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords once\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define stopwords and filler words\n",
        "filler_words = ['uh', 'um', 'you know', 'like', 'I mean', 'uhh', 'hmm', 'pardon me','excuse me','ah','oh','kind of','sort of','well','basically','actually','so','so yeah','to be honest','to tell you the truth','if you know what I mean',\"as I was saying\",\"I don't know\",\"probably\"] # Add more as needed\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove anything between < and >, including the brackets\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove filler words\n",
        "    filler_pattern = r'\\b(?:' + '|'.join(filler_words) + r')\\b'\n",
        "    text = re.sub(filler_pattern, '', text)\n",
        "\n",
        "    # Remove special characters and extra spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove common stopwords\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Join words back to a single string\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Sample input text (long conversation)\n",
        "input_text = concatenated_text\n",
        "\n",
        "# Preprocess the text\n",
        "cleaned_text = preprocess_text(input_text)\n",
        "\n",
        "# Output the cleaned text\n",
        "print(\"Cleaned Text:\\n\", cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4bmhH-03OIT",
        "outputId": "5110c1bd-cb32-48b9-8a33-02af8e3bac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " okay bout california yeah big broad theres lot lot job opportunities states pretty much big theres lot traffic maybe violence rate bad news even though wanna know whats going environment still watch look see whats going daily basis sociology two year degree liberal arts major sociology im mta bus operator since metro steady growing dream job move company im start classes supervisory next week cause look promote within company thats good thing theres lot opportunities metro take classes theyll pay tuition things nature thanks hard right easy take advantage right cause look promote within since im already working thats good thing good go ahead take classes need youre interested go ahead move ladder soon possible mean im sorry okay read take long walk hot bath meditate close eyes sometimes im pretty much good see bus operator run circumstances situations gotta remain calm still remain professional time look goes mean comes experience something continuous basis usually somewhere line become good look ive driving years dealing public handle circumstances treat people wanna treated im pretty good maybe younger get older get wiser learn different things im still learning today would say family kids even though lot deaths around thats go thats part life experience born gotta leave one day kids keep sane love family thank setting good examples youre first teacher wanna set positive good example kids think thats good thing starts home first teacher kids youre youre one see daily basis wake whatevers taught home lookin learning every day whether home school people kids tendency things see mean try keep positive teach em good morals values get along people regardless race different things nature four half year old son seven year old daughter also twenty three year old yeah im bout daughters pregnant boy three little girls three grandkids one way boy time yeah thank hardest thing right im single parent makes hard alone expensive times depends persons situation whether help job things nature help situation better hard try keep job keep food house maintain support kids best way kids period whats memorable im one family degree kinda yeah kinda even though im baby ten kids ive always kept back mind even though everybody pretty much whole family decent job im one degree kinda gave pat back thats thing remember graduating family support thank happy accomplished something even though may much better high school diploma working bachelors degree ended bad car accident never went back got distracted working time moreso needed income schooling time young parent cause daughter seventeen needed money support never went back feel never late feel ill take classes im metro help move ladder thats im starting class next week thank hm advice wouldve gave wouldnt young mother young age wouldve stayed school let accident distract wouldve remained school wouldnt kids early rather wouldve stayed school part time job something feel education excellent thing person knowledge learning different things keeping mind open learning new ideas every day think thats plus anybodys shoes better selves education maybe maybe promote within company whatever case may help better career im quite sure learn mistakes time dont continue make ones feel okay make mistake long something change even though im going school late still im going wanna better career wise yes oldest daughter argument life shes living right things shes going told needed make changes better situation got argument kids sometimes dont wanna hear hear stuff youre saying even though true dont wanna hear may going something dont wanna hear got argument happened told im im sorry close close situation daughters needs make changes better life ill telling shes shes kinda stubborn way raised listen mom moms gonna tell nothing wrong ive telling years different things kinda talking wall opposite shes regretting cause shes mom told mom im opposite guess gotta bump head couple times get kinda done told done left alone make change frustrating im talking wall shes hearing im seem taking forever change left individual whenever theyre ready mean person get tired something theyll make change may want happen ball court much wow days since two little ones kinda trained go bed eight clock gotta go school think important good nights rest kinda kinda gets ready next day gonna feel rested type person youll day cause everybody days whether theyre good bad thats part life feel good nights good good nights rest hopefully youll good day pretty much need rest im driving bus dealing people job stressful feel im rested itll help irritated tired lazy feel wanna lay go sleep get rest need never thought cause said everybody moments never thought hm dont really best friend person deal used work would tell im outgoing go getter dependable responsible im people person get along others im kinda leave good good mark whether know youd say seems nice young lady whatever something thank try stay happy id rather happy sad kids keep going mean especially go pick school hey mom kinda make day run happy excited mean thank youre welcome good day goodbye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "463-F7oF3bOr",
        "outputId": "9367db01-a8a4-494b-8222-2aa4f796449f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "856"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.read_csv('/content/305_TRANSCRIPT.csv',sep = '\\t')\n",
        "df_.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eFFv4e6DxnO2",
        "outputId": "cb898388-b497-4008-dda7-77df003414ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   start_time  stop_time      speaker  \\\n",
              "0      28.655     40.645        Ellie   \n",
              "1      41.355     50.955        Ellie   \n",
              "2      51.625     52.785        Ellie   \n",
              "3      53.245     54.445  Participant   \n",
              "4      55.045     55.835        Ellie   \n",
              "\n",
              "                                               value  \n",
              "0  hi i'm ellie thanks for coming in today i was ...  \n",
              "1  i'm here to learn about people and would love ...  \n",
              "2                            how are you doing today  \n",
              "3                                  i'm doing alright  \n",
              "4                                        that's good  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-475eece1-5ef1-4efa-bc5a-d62b85990aa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>stop_time</th>\n",
              "      <th>speaker</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.655</td>\n",
              "      <td>40.645</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>hi i'm ellie thanks for coming in today i was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.355</td>\n",
              "      <td>50.955</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>i'm here to learn about people and would love ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51.625</td>\n",
              "      <td>52.785</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>how are you doing today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.245</td>\n",
              "      <td>54.445</td>\n",
              "      <td>Participant</td>\n",
              "      <td>i'm doing alright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.045</td>\n",
              "      <td>55.835</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>that's good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-475eece1-5ef1-4efa-bc5a-d62b85990aa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-475eece1-5ef1-4efa-bc5a-d62b85990aa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-475eece1-5ef1-4efa-bc5a-d62b85990aa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ca38415-8a8b-4b0c-b6cd-afda3b7e37c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ca38415-8a8b-4b0c-b6cd-afda3b7e37c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ca38415-8a8b-4b0c-b6cd-afda3b7e37c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_",
              "summary": "{\n  \"name\": \"df_\",\n  \"rows\": 405,\n  \"fields\": [\n    {\n      \"column\": \"start_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 497.38534959286096,\n        \"min\": 28.655,\n        \"max\": 1678.775,\n        \"num_unique_values\": 405,\n        \"samples\": [\n          264.805,\n          889.755,\n          1608.645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stop_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 497.49278384379073,\n        \"min\": 40.645,\n        \"max\": 1679.805,\n        \"num_unique_values\": 404,\n        \"samples\": [\n          265.715,\n          890.995,\n          1610.505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Participant\",\n          \"Ellie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 315,\n        \"samples\": [\n          \"has that gotten you in trouble\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preset_speaker = \"Participant\"\n",
        "filtered_rows = df_[df_['speaker'] == preset_speaker]\n",
        "concatenated_text_2 = ' '.join(filtered_rows['value'].astype(str))\n",
        "print(concatenated_text_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-LB7raCyZcD",
        "outputId": "74b0c0fe-1514-4645-d38d-0ebe9c73efa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i'm doing alright uh originally i'm from california uh born in glendale i'm not too happy with it uh just unemployed at the moment but uh actively seeking uh uh doing what i'm supposed to be doing uh there are some uh  some prospects there but hopefully i'll learn something today yeah well i have one it's a girlfriend so i consider her a roommate a lover type thing pardon me um we're pretty close uh i met her last year and uh we've been through some troubling times but uh we're starting to see a light at the end of the tunnel uh the troubling times uh i would let me see uh well i had uh gotten a d_u_i last year and uh lost my job i'm a truck driver by trade so  uh that kinda threw me way off uh having a fourteen hundred dollar a week job uh and then going to nothing kinda like plus losing my my license kinda really threw me off and uh I couldn't um i haven't really uh found anything that i was interested in uh so i started cooking and our trying to see which other route i can go as far as uh having some kind of a career and uh so i'm choose choosing to go into the culinary field but you know uh meanwhile i still have to work it's hard to find work with uh without going to school  and uh so but i think today uh i applied at ralphs so hopefully i'll get that job i should have that job actually so um but i'm starting to see a light like i said at the end of the tunnel now a little by little my dream job would be probably forestry service out in the wilderness yeah i like being alone pardon me well you know i have a a lot of for animals i'm an exotic animal trainer by trade and uh so and i like  being i don't like people too much uh so being outdoors and uh i've always enjoyed being outdoors that's how i like being a truck driver i've traveled the world i don't necessarily like being in a warehouse or an office i'm of a a outdoors type of guy so uh one of my trips would be uh i spent a year and a half in japan and uh on the uh lower island uh there that uh they built that bridge  uh the largest bridge in the world uh and uh i went there to work for  uh for an all white oh uh an all white tiger act and uh working for a japanese circus  so it was interesting that a lot of people on that island hadn't really seen a lot of americans  'cause that was also one of the islands that we uh that they bombed  so there was a lot of negativity but i i pretty have a good idea out you know outlook uh on life uh especially during those times you know i i enjoyed myself you know through all the traveling and and meeting new people and um eating you know different um diverse foods and uh it was a good experience for me  all of that whole experience was pretty good for me you know just traveling around with circuses and uh  you know it's been great uh probably um one some of the things i like about l_a there's not a lot that i like about l_a but um i like hollywood i like the the the movie industry um the uh huge uh um different different people you know different uh different ethnics of uh people here you know uh i enjoy talking to uh few you know a lot of foreigners you know i like to see where they came from and and what what it's like there  traffic's atrocious you know traffic <laughter> uh ignorance uh being disrespected uh being disrespectful or whatever you know other people being disrespectful toward you or other people um that's about it dishonesty pardon me uh it happens on a daily basis it seems like you know i ride the bus a lot so uh you know or i if i'm riding my bike uh people tend to almost run me over so if i'm not totally paying attention to traffic uh you know i find myself sometimes you know having to wait to see what they're gonna do instead of i having the right of way or uh something like that yeah big time what do i do when i'm annoyed um probably sit there and uh sit there and vent you know uh speak my mind even though a lot of times it's i'm myself you know just like you know assholes or whatever you um well you know i carry rocks in my back pocket so i can it you know it happens so much where i i just it just amazes me at what people will do sometimes you know you almost get run over all you know i i probably almost get run over probably on a daily basis   and if i wasn't paying attention i'd be up shit creek uh it's hard with dealing with people especially trying not to react 'cause there's consequences for your reactions um it was with my girlfriend and uh it was about being honest uh  um i'm pretty honest with i'm open and honest about any anything and everything and uh what it was about was uh just her lying to me uh telling me that she had told our landlord something and and that she had done something and that and that aspect and i come to find out a week later that it was a total lie so i just you know didn't like that at all pardon me um i'm trying to i'm missing the word for it uh just that i don't know now that whether i could believe anything she says now so it was it was uh i felt hurt you know uh that you know here we had been in a relationship for a little bit and well that's probably one of my biggest uh pet peeves is is being honest  um i don't like i said i don't hold back and i'm pretty honest in anything and everything that i do or say so you know and if you're lying about something well you just you're always having to cover up uh more lies with the lies that that you already told and i just don't see any you know so it kinda took a lot from uh me trusting her now or you know whatever now i'm i you know is it truthful is it not you know so it's kinda hurt our relationship can't do nothing about it uh fun i like going to the beach uh i love shooting darts but i haven't done it in a while i i love i love to paint uh i got into watercolor painting  and i'm pretty gifted at that and um uh i wanna try some other mediums and uh let's see here i love fishing uh haven't gone in a while though and uh i like driving a truck you know uh it's you know my job you know i was a i really really enjoyed it i don't like driving through cities but uh usually when i'm in the middle of the night where i can see all the stars i like star gazing i'll see if i can um pick out some of those uh astronomy uh stars up up there and um  i'm a pretty easy going guy so shooting pool um sunshine just those i like uh most memorable experiences um good or bad uh most memorable experiences uh probably uh playing with lions and tigers uh uh wrestling a a baby elephant in a in a mud puddle uh uh just enjoying myself i know not uh i don't have much family as it is uh at least here in the states i don't my mom's from central america so uh  but i'm not close to i have uh  three brothers one sister and i'm probably not really really close to none of my siblings i speak with one brother uh quite a bit um my other youngest brother you know he he just i'd just rather not  you know i converse <con> converse with him but it's you know just i try to keep it on a professional basis my sister i don't talk to at all my my other brother underneath me i haven't spoken to him in years so i'm just close with my mom uh my niece some of my nephews and that's about it have i done anything to avoid it um to avoid them uh yeah i just don't talk to them i don't call them i don't ask about them i you know i talk to my mom quite a bit my brother quite a bit but i just don't bring up those subjects or if they are brought up i just usually say you know that's on them and i really don't wanna deal with them so um it's been hard lately it's been probably hard for the last uh going on a year um you know i uh depends on my thought process at the time i like i said i've been looking for work quite a bit um so just wondering why you know i don't get called i i just have my i have racing thoughts  so  or i get depressed you know 'cause i or i worry about things that you know that really i have no control over so i don't lately i just been sleeping a bit too much uh at least for me because i'm so used to just sleeping four to five hours a a a night but now it's changed to about eight to nine hours and i'm still tired uh lately i have been probably about the last few months um tired <laughter> um i you know if i don't sleep well sometimes then i just dwell back on the same things that have been bothering me so you know i'm more of a guy you know i love to work um and if i'm not then it's just a little bit too much time for me to spend in my own head and so you know um i there i either if i'm busy or i'm doing what i you know in whatever job i do i kinda you know get to it i enjoy it uh it's something new for me and uh so i can think about you know either work or i think of home and then think about this you know i don't have to worry about you know um money um you know bills are getting paid and i can just concentrate on other things either you know do the things i like or mm you know maybe spending a little bit more time with my girlfriend or you know so something like that  how do i what how do i cope with them um i just try not to think about it uh it's it's not about whether coping with it or not um i just do it's uh i'm more of a guy that just you know it may take me a moment to to um say that i'm coping with something but you know it it's if i have no control over it there's nothing that i can really do about it the only thing i can do is control to do what i'm doing and that's actively looking for work uh actively going out on uh  interviews uh talking with others about work so that i can just kinda you know get back to um back to basics you know i just don't let a lot of stuff bother me it does bother me but i try not to to let it continue to bother me if what has gotten me in trouble my mood swing i mean um yeah money i mean you know my past i i got a past history so uh which kinda tends to uh uh bother my uh my hiring process i don't know if i'm gonna get hired so i gotta deal with uh different different type of employers who are uh say uh felony friendly and uh uh stuff like that and i try you know i i've taken classes on uh  on uh how to interview how to uh how to answer some of the questions which you know come up quite a bit and uh i kinda reflect back on that but i just uh i gotta keep putting to my head that that's not who  who i wanna be anymore so or you know i i've done  uh i've done uh i've done my time uh so to say but uh i took the time you know the last time i just took a lot of time and  and try to uh work on the issues that were bothering me so um you know toward positive stuff i got my g_e_d different things a lot of classes um uh thought about going to school  i didn't go to school and uh anything that would kinda um change my old ways and and uh and try to move on to more productive activities  pardon me i still didn't hear you that people have been deceitful can you repeat that one more time alright uh i've been diagnosed with uh bipolarism um it's tough if you don't you know um i don't medicate so i mean i have been on medication before  in the past but <sniff> um again it's i try to live on life uh i try to live life on life's terms  and i just you know um i know the medical establishments always wanna label something and  and what i don't like about it is that they just experiment with pills you know i've been on probably every imaginable pill that there is for that and um you know some of them have been too strong or some of them not strong enough and so i just try to cope with things uh um it's just my life skills you know i i don't i don't wanna be using drug i know certain drugs work for like three to four months six months  and then they go well here i'm gonna try you on this and or i'm gonna try you on that  and it's just an ongoing process and i probably for about the last two years actually about three years i kinda just said you know what that's it and um whether it's different than whether if i would be on on on uhon meds for it   um i don't think so you know it's the still the same stuff i still get the same problems and i still  uh get the same anxiety as if i if i was on medication for it or not so i just and i'll deal with it you know sometimes it's not good you know i get irritated at people a lot i don't like people um i don't like crowds i don't you know like obnoxious people huge empty quiet so um but i i get a person you know i it's not that personality but i think people can see me and just say uh don't mess with this guy or you know um but still you know i like i i ride public transportation quite a bit and um you know you just get a lot of loud obnoxious people on there sometimes i gotta get off the bus that's how i deal with with with with people because i just know there's consequences if i if i didn't deal with it that way  so i just let it go i'd rather take the time on getting off the bus waiting for the next bus and hopefully it's not that bad  did i have a problem before i got out uh well i  i don't know if i knew that i had a problem um uh before i found out the thing is that i know other people  um i have a lot of ups and downs so i know a lot in my younger days people would tell me you know when i told them that i was diagnosed with you know bipolar that um  a lot of remarks were like oh that's what's wrong you know that's what was wrong with you we we wish that you would've would've found that out years ago  uh and uh like i don't think the meds really work but what i do uh i think uh time kinda like you know just getting older kind of uh you know makes it work you know me me dealing with life so pardon me uh i talked to a therapist probably on a weekly basis for a while uh recently and uh it helps a lot you know uh just to get out my anger uh my thoughts um a lot of people may not understand that but uh a therapist is i think the bigger thing is that i can just get it all out uh whatever's bothing me whether it be uh people you know uh uh other issues you know were whatever the case may be  i just think talking about it and they're such good listeners and can kinda like you know they they give me the same advice that you know that i you know give myself or whatever that i would give to others uh but it's always helpful if you hear it from somebody else somebody who will be has a you know are are you know they go to school for this so  you know but it's good to have yeah well i don't go anymore uh so um i kinda miss it you know like i said uh uh i miss it a lot actually but uh it's just one of those things you know i just deal with it you know uh according to you know if i ever get a chance to go to therapy again i probably will um well monetary reasons and uh you know uh i don't have health insurance there's a lot of things that you know i'd like to do but i can't you know um  you know money situation's not that great right now so how does my friends describe me um they would probably describe me as uh uh energetic uh outgoing person uh once i get to know people um laughs i you know i laugh a i laugh a lot um but uh they would probably tell you that i'm also very serious and uh  uh hidden person i don't reveal a lot you know and uh so  someone who has been a positive influence in my life someone who's been um someone who's been a positive influence in my life uh probably my boss one of my bosses uh when i first started with uh with exotic animals he was real you know he was uh uh german and um they didn't teach i don't know what he saw in me but he taught me a lot about working with exotic animals and um showed a lot of confidence in me and which in in it also built confidence in myself  and uh sort of let me know that you know that there's nothing that i really can't accomplish if i put my mind to it you know yeah it was you're welcome bye <laughter>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# Define stopwords and filler words\n",
        "filler_words = ['uh', 'um', 'you know', 'like', 'I mean', 'uhh', 'hmm', 'pardon me','excuse me','ah','oh','kind of','sort of','well','basically','actually','so','so yeah','to be honest','to tell you the truth','if you know what I mean',\"as I was saying\",\"I don't know\",\"probably\"]\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    filler_pattern = r'\\b(?:' + '|'.join(filler_words) + r')\\b'\n",
        "    text = re.sub(filler_pattern, '', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text\n",
        "\n",
        "# Sample input text (long conversation)\n",
        "input_text = concatenated_text_2\n",
        "# Preprocess the text\n",
        "cleaned_text_2 = preprocess_text(input_text)\n",
        "\n",
        "# Output the cleaned text\n",
        "print(\"Cleaned Text:\\n\", cleaned_text_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL05-NY22A9A",
        "outputId": "736f881d-5fdb-4e32-a2f3-78f1b17901c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " im doing alright originally im from california born in glendale im not too happy with it just unemployed at the moment but actively seeking doing what im supposed to be doing there are some some prospects there but hopefully ill learn something today yeah i have one its a girlfriend i consider her a roommate a lover type thing were pretty close i met her last year and weve been through some troubling times but were starting to see a light at the end of the tunnel the troubling times i would let me see i had gotten a dui last year and lost my job im a truck driver by trade that kinda threw me way off having a fourteen hundred dollar a week job and then going to nothing kinda plus losing my my license kinda really threw me off and i couldnt i havent really found anything that i was interested in i started cooking and our trying to see which other route i can go as far as having some a career and im choose choosing to go into the culinary field but meanwhile i still have to work its hard to find work with without going to school and but i think today i applied at ralphs hopefully ill get that job i should have that job but im starting to see a light i said at the end of the tunnel now a little by little my dream job would be forestry service out in the wilderness yeah i being alone i have a a lot of for animals im an exotic animal trainer by trade and and i being i dont people too much being outdoors and ive always enjoyed being outdoors thats how i being a truck driver ive traveled the world i dont necessarily being in a warehouse or an office im of a a outdoors type of guy one of my trips would be i spent a year and a half in japan and on the lower island there that they built that bridge the largest bridge in the world and i went there to work for for an all white an all white tiger act and working for a japanese circus it was interesting that a lot of people on that island hadnt really seen a lot of americans cause that was also one of the islands that we that they bombed there was a lot of negativity but i i pretty have a good idea out outlook on life especially during those times i i enjoyed myself through all the traveling and and meeting new people and eating different diverse foods and it was a good experience for me all of that whole experience was pretty good for me just traveling around with circuses and its been great one some of the things i about la theres not a lot that i about la but i hollywood i the the the movie industry the huge different different people different different ethnics of people here i enjoy talking to few a lot of foreigners i to see where they came from and and what what its there traffics atrocious traffic ignorance being disrespected being disrespectful or whatever other people being disrespectful toward you or other people thats about it dishonesty it happens on a daily basis it seems i ride the bus a lot or i if im riding my bike people tend to almost run me over if im not totally paying attention to traffic i find myself sometimes having to wait to see what theyre gonna do instead of i having the right of way or something that yeah big time what do i do when im annoyed sit there and sit there and vent speak my mind even though a lot of times its im myself just assholes or whatever you i carry rocks in my back pocket i can it it happens much where i i just it just amazes me at what people will do sometimes you almost get run over all i i almost get run over on a daily basis and if i wasnt paying attention id be up shit creek its hard with dealing with people especially trying not to react cause theres consequences for your reactions it was with my girlfriend and it was about being honest im pretty honest with im open and honest about any anything and everything and what it was about was just her lying to me telling me that she had told our landlord something and and that she had done something and that and that aspect and i come to find out a week later that it was a total lie i just didnt that at all im trying to im missing the word for it just that i dont know now that whether i could believe anything she says now it was it was i felt hurt that here we had been in a relationship for a little bit and thats one of my biggest pet peeves is is being honest i dont i said i dont hold back and im pretty honest in anything and everything that i do or say and if youre lying about something you just youre always having to cover up more lies with the lies that that you already told and i just dont see any it kinda took a lot from me trusting her now or whatever now im i is it truthful is it not its kinda hurt our relationship cant do nothing about it fun i going to the beach i love shooting darts but i havent done it in a while i i love i love to paint i got into watercolor painting and im pretty gifted at that and i wanna try some other mediums and lets see here i love fishing havent gone in a while though and i driving a truck its my job i was a i really really enjoyed it i dont driving through cities but usually when im in the middle of the night where i can see all the stars i star gazing ill see if i can pick out some of those astronomy stars up up there and im a pretty easy going guy shooting pool sunshine just those i most memorable experiences good or bad most memorable experiences playing with lions and tigers wrestling a a baby elephant in a in a mud puddle just enjoying myself i know not i dont have much family as it is at least here in the states i dont my moms from central america but im not close to i have three brothers one sister and im not really really close to none of my siblings i speak with one brother quite a bit my other youngest brother he he just id just rather not i converse converse with him but its just i try to keep it on a professional basis my sister i dont talk to at all my my other brother underneath me i havent spoken to him in years im just close with my mom my niece some of my nephews and thats about it have i done anything to avoid it to avoid them yeah i just dont talk to them i dont call them i dont ask about them i i talk to my mom quite a bit my brother quite a bit but i just dont bring up those subjects or if they are brought up i just usually say thats on them and i really dont wanna deal with them its been hard lately its been hard for the last going on a year i depends on my thought process at the time i i said ive been looking for work quite a bit just wondering why i dont get called i i just have my i have racing thoughts or i get depressed cause i or i worry about things that that really i have no control over i dont lately i just been sleeping a bit too much at least for me because im used to just sleeping four to five hours a a a night but now its changed to about eight to nine hours and im still tired lately i have been about the last few months tired i if i dont sleep sometimes then i just dwell back on the same things that have been bothering me im more of a guy i love to work and if im not then its just a little bit too much time for me to spend in my own head and i there i either if im busy or im doing what i in whatever job i do i kinda get to it i enjoy it its something new for me and i can think about either work or i think of home and then think about this i dont have to worry about money bills are getting paid and i can just concentrate on other things either do the things i or mm maybe spending a little bit more time with my girlfriend or something that how do i what how do i cope with them i just try not to think about it its its not about whether coping with it or not i just do its im more of a guy that just it may take me a moment to to say that im coping with something but it its if i have no control over it theres nothing that i can really do about it the only thing i can do is control to do what im doing and thats actively looking for work actively going out on interviews talking with others about work that i can just kinda get back to back to basics i just dont let a lot of stuff bother me it does bother me but i try not to to let it continue to bother me if what has gotten me in trouble my mood swing i mean yeah money i mean my past i i got a past history which kinda tends to bother my my hiring process i dont know if im gonna get hired i gotta deal with different different type of employers who are say felony friendly and stuff that and i try i ive taken classes on on how to interview how to how to answer some of the questions which come up quite a bit and i kinda reflect back on that but i just i gotta keep putting to my head that thats not who who i wanna be anymore or i ive done ive done ive done my time to say but i took the time the last time i just took a lot of time and and try to work on the issues that were bothering me toward positive stuff i got my ged different things a lot of classes thought about going to school i didnt go to school and anything that would kinda change my old ways and and and try to move on to more productive activities i still didnt hear you that people have been deceitful can you repeat that one more time alright ive been diagnosed with bipolarism its tough if you dont i dont medicate i mean i have been on medication before in the past but again its i try to live on life i try to live life on lifes terms and i just i know the medical establishments always wanna label something and and what i dont about it is that they just experiment with pills ive been on every imaginable pill that there is for that and some of them have been too strong or some of them not strong enough and i just try to cope with things its just my life skills i i dont i dont wanna be using drug i know certain drugs work for three to four months six months and then they go here im gonna try you on this and or im gonna try you on that and its just an ongoing process and i for about the last two years about three years i kinda just said what thats it and whether its different than whether if i would be on on on uhon meds for it i dont think its the still the same stuff i still get the same problems and i still get the same anxiety as if i if i was on medication for it or not i just and ill deal with it sometimes its not good i get irritated at people a lot i dont people i dont crowds i dont obnoxious people huge empty quiet but i i get a person i its not that personality but i think people can see me and just say dont mess with this guy or but still i i i ride public transportation quite a bit and you just get a lot of loud obnoxious people on there sometimes i gotta get off the bus thats how i deal with with with with people because i just know theres consequences if i if i didnt deal with it that way i just let it go id rather take the time on getting off the bus waiting for the next bus and hopefully its not that bad did i have a problem before i got out i i dont know if i knew that i had a problem before i found out the thing is that i know other people i have a lot of ups and downs i know a lot in my younger days people would tell me when i told them that i was diagnosed with bipolar that a lot of remarks were thats whats wrong thats what was wrong with you we we wish that you wouldve wouldve found that out years ago and i dont think the meds really work but what i do i think time kinda just getting older makes it work me me dealing with life i talked to a therapist on a weekly basis for a while recently and it helps a lot just to get out my anger my thoughts a lot of people may not understand that but a therapist is i think the bigger thing is that i can just get it all out whatevers bothing me whether it be people other issues were whatever the case may be i just think talking about it and theyre such good listeners and can kinda they they give me the same advice that that i give myself or whatever that i would give to others but its always helpful if you hear it from somebody else somebody who will be has a are are they go to school for this but its good to have yeah i dont go anymore i kinda miss it i said i miss it a lot but its just one of those things i just deal with it according to if i ever get a chance to go to therapy again i will monetary reasons and i dont have health insurance theres a lot of things that id to do but i cant money situations not that great right now how does my friends describe me they would describe me as energetic outgoing person once i get to know people laughs i i laugh a i laugh a lot but they would tell you that im also very serious and hidden person i dont reveal a lot and someone who has been a positive influence in my life someone whos been someone whos been a positive influence in my life my boss one of my bosses when i first started with with exotic animals he was real he was german and they didnt teach i dont know what he saw in me but he taught me a lot about working with exotic animals and showed a lot of confidence in me and which in in it also built confidence in myself and let me know that that theres nothing that i really cant accomplish if i put my mind to it yeah it was youre welcome bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtBqq_1O2ZwT",
        "outputId": "585c0dca-27ec-4a92-95eb-1603ff557c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2714"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id = [303,305]\n",
        "text = [cleaned_text,cleaned_text_2]\n",
        "label = [0,0]\n",
        "data = {\n",
        "    'id': id,\n",
        "    'cleaned_text': text,\n",
        "    'label': label\n",
        "}\n",
        "df_test = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "iRi6Z71E2ed8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test\n"
      ],
      "metadata": {
        "id": "SGJLibEtCrWV",
        "outputId": "7de60ebf-4264-4845-cfae-cfcc7bc06d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                       cleaned_text  label\n",
              "0  303  okay bout california yeah big broad theres lot...      0\n",
              "1  305  im doing alright originally im from california...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89fd906f-5ae0-416b-98b2-9251c2516101\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>303</td>\n",
              "      <td>okay bout california yeah big broad theres lot...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>305</td>\n",
              "      <td>im doing alright originally im from california...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89fd906f-5ae0-416b-98b2-9251c2516101')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89fd906f-5ae0-416b-98b2-9251c2516101 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89fd906f-5ae0-416b-98b2-9251c2516101');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a701781-9bff-47be-b8f7-d3957f2647b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a701781-9bff-47be-b8f7-d3957f2647b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a701781-9bff-47be-b8f7-d3957f2647b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6131736d-7f54-41f7-b5cc-cb36954deb44\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6131736d-7f54-41f7-b5cc-cb36954deb44 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 303,\n        \"max\": 305,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          305,\n          303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"im doing alright originally im from california born in glendale im not too happy with it just unemployed at the moment but actively seeking doing what im supposed to be doing there are some some prospects there but hopefully ill learn something today yeah i have one its a girlfriend i consider her a roommate a lover type thing were pretty close i met her last year and weve been through some troubling times but were starting to see a light at the end of the tunnel the troubling times i would let me see i had gotten a dui last year and lost my job im a truck driver by trade that kinda threw me way off having a fourteen hundred dollar a week job and then going to nothing kinda plus losing my my license kinda really threw me off and i couldnt i havent really found anything that i was interested in i started cooking and our trying to see which other route i can go as far as having some a career and im choose choosing to go into the culinary field but meanwhile i still have to work its hard to find work with without going to school and but i think today i applied at ralphs hopefully ill get that job i should have that job but im starting to see a light i said at the end of the tunnel now a little by little my dream job would be forestry service out in the wilderness yeah i being alone i have a a lot of for animals im an exotic animal trainer by trade and and i being i dont people too much being outdoors and ive always enjoyed being outdoors thats how i being a truck driver ive traveled the world i dont necessarily being in a warehouse or an office im of a a outdoors type of guy one of my trips would be i spent a year and a half in japan and on the lower island there that they built that bridge the largest bridge in the world and i went there to work for for an all white an all white tiger act and working for a japanese circus it was interesting that a lot of people on that island hadnt really seen a lot of americans cause that was also one of the islands that we that they bombed there was a lot of negativity but i i pretty have a good idea out outlook on life especially during those times i i enjoyed myself through all the traveling and and meeting new people and eating different diverse foods and it was a good experience for me all of that whole experience was pretty good for me just traveling around with circuses and its been great one some of the things i about la theres not a lot that i about la but i hollywood i the the the movie industry the huge different different people different different ethnics of people here i enjoy talking to few a lot of foreigners i to see where they came from and and what what its there traffics atrocious traffic ignorance being disrespected being disrespectful or whatever other people being disrespectful toward you or other people thats about it dishonesty it happens on a daily basis it seems i ride the bus a lot or i if im riding my bike people tend to almost run me over if im not totally paying attention to traffic i find myself sometimes having to wait to see what theyre gonna do instead of i having the right of way or something that yeah big time what do i do when im annoyed sit there and sit there and vent speak my mind even though a lot of times its im myself just assholes or whatever you i carry rocks in my back pocket i can it it happens much where i i just it just amazes me at what people will do sometimes you almost get run over all i i almost get run over on a daily basis and if i wasnt paying attention id be up shit creek its hard with dealing with people especially trying not to react cause theres consequences for your reactions it was with my girlfriend and it was about being honest im pretty honest with im open and honest about any anything and everything and what it was about was just her lying to me telling me that she had told our landlord something and and that she had done something and that and that aspect and i come to find out a week later that it was a total lie i just didnt that at all im trying to im missing the word for it just that i dont know now that whether i could believe anything she says now it was it was i felt hurt that here we had been in a relationship for a little bit and thats one of my biggest pet peeves is is being honest i dont i said i dont hold back and im pretty honest in anything and everything that i do or say and if youre lying about something you just youre always having to cover up more lies with the lies that that you already told and i just dont see any it kinda took a lot from me trusting her now or whatever now im i is it truthful is it not its kinda hurt our relationship cant do nothing about it fun i going to the beach i love shooting darts but i havent done it in a while i i love i love to paint i got into watercolor painting and im pretty gifted at that and i wanna try some other mediums and lets see here i love fishing havent gone in a while though and i driving a truck its my job i was a i really really enjoyed it i dont driving through cities but usually when im in the middle of the night where i can see all the stars i star gazing ill see if i can pick out some of those astronomy stars up up there and im a pretty easy going guy shooting pool sunshine just those i most memorable experiences good or bad most memorable experiences playing with lions and tigers wrestling a a baby elephant in a in a mud puddle just enjoying myself i know not i dont have much family as it is at least here in the states i dont my moms from central america but im not close to i have three brothers one sister and im not really really close to none of my siblings i speak with one brother quite a bit my other youngest brother he he just id just rather not i converse converse with him but its just i try to keep it on a professional basis my sister i dont talk to at all my my other brother underneath me i havent spoken to him in years im just close with my mom my niece some of my nephews and thats about it have i done anything to avoid it to avoid them yeah i just dont talk to them i dont call them i dont ask about them i i talk to my mom quite a bit my brother quite a bit but i just dont bring up those subjects or if they are brought up i just usually say thats on them and i really dont wanna deal with them its been hard lately its been hard for the last going on a year i depends on my thought process at the time i i said ive been looking for work quite a bit just wondering why i dont get called i i just have my i have racing thoughts or i get depressed cause i or i worry about things that that really i have no control over i dont lately i just been sleeping a bit too much at least for me because im used to just sleeping four to five hours a a a night but now its changed to about eight to nine hours and im still tired lately i have been about the last few months tired i if i dont sleep sometimes then i just dwell back on the same things that have been bothering me im more of a guy i love to work and if im not then its just a little bit too much time for me to spend in my own head and i there i either if im busy or im doing what i in whatever job i do i kinda get to it i enjoy it its something new for me and i can think about either work or i think of home and then think about this i dont have to worry about money bills are getting paid and i can just concentrate on other things either do the things i or mm maybe spending a little bit more time with my girlfriend or something that how do i what how do i cope with them i just try not to think about it its its not about whether coping with it or not i just do its im more of a guy that just it may take me a moment to to say that im coping with something but it its if i have no control over it theres nothing that i can really do about it the only thing i can do is control to do what im doing and thats actively looking for work actively going out on interviews talking with others about work that i can just kinda get back to back to basics i just dont let a lot of stuff bother me it does bother me but i try not to to let it continue to bother me if what has gotten me in trouble my mood swing i mean yeah money i mean my past i i got a past history which kinda tends to bother my my hiring process i dont know if im gonna get hired i gotta deal with different different type of employers who are say felony friendly and stuff that and i try i ive taken classes on on how to interview how to how to answer some of the questions which come up quite a bit and i kinda reflect back on that but i just i gotta keep putting to my head that thats not who who i wanna be anymore or i ive done ive done ive done my time to say but i took the time the last time i just took a lot of time and and try to work on the issues that were bothering me toward positive stuff i got my ged different things a lot of classes thought about going to school i didnt go to school and anything that would kinda change my old ways and and and try to move on to more productive activities i still didnt hear you that people have been deceitful can you repeat that one more time alright ive been diagnosed with bipolarism its tough if you dont i dont medicate i mean i have been on medication before in the past but again its i try to live on life i try to live life on lifes terms and i just i know the medical establishments always wanna label something and and what i dont about it is that they just experiment with pills ive been on every imaginable pill that there is for that and some of them have been too strong or some of them not strong enough and i just try to cope with things its just my life skills i i dont i dont wanna be using drug i know certain drugs work for three to four months six months and then they go here im gonna try you on this and or im gonna try you on that and its just an ongoing process and i for about the last two years about three years i kinda just said what thats it and whether its different than whether if i would be on on on uhon meds for it i dont think its the still the same stuff i still get the same problems and i still get the same anxiety as if i if i was on medication for it or not i just and ill deal with it sometimes its not good i get irritated at people a lot i dont people i dont crowds i dont obnoxious people huge empty quiet but i i get a person i its not that personality but i think people can see me and just say dont mess with this guy or but still i i i ride public transportation quite a bit and you just get a lot of loud obnoxious people on there sometimes i gotta get off the bus thats how i deal with with with with people because i just know theres consequences if i if i didnt deal with it that way i just let it go id rather take the time on getting off the bus waiting for the next bus and hopefully its not that bad did i have a problem before i got out i i dont know if i knew that i had a problem before i found out the thing is that i know other people i have a lot of ups and downs i know a lot in my younger days people would tell me when i told them that i was diagnosed with bipolar that a lot of remarks were thats whats wrong thats what was wrong with you we we wish that you wouldve wouldve found that out years ago and i dont think the meds really work but what i do i think time kinda just getting older makes it work me me dealing with life i talked to a therapist on a weekly basis for a while recently and it helps a lot just to get out my anger my thoughts a lot of people may not understand that but a therapist is i think the bigger thing is that i can just get it all out whatevers bothing me whether it be people other issues were whatever the case may be i just think talking about it and theyre such good listeners and can kinda they they give me the same advice that that i give myself or whatever that i would give to others but its always helpful if you hear it from somebody else somebody who will be has a are are they go to school for this but its good to have yeah i dont go anymore i kinda miss it i said i miss it a lot but its just one of those things i just deal with it according to if i ever get a chance to go to therapy again i will monetary reasons and i dont have health insurance theres a lot of things that id to do but i cant money situations not that great right now how does my friends describe me they would describe me as energetic outgoing person once i get to know people laughs i i laugh a i laugh a lot but they would tell you that im also very serious and hidden person i dont reveal a lot and someone who has been a positive influence in my life someone whos been someone whos been a positive influence in my life my boss one of my bosses when i first started with with exotic animals he was real he was german and they didnt teach i dont know what he saw in me but he taught me a lot about working with exotic animals and showed a lot of confidence in me and which in in it also built confidence in myself and let me know that that theres nothing that i really cant accomplish if i put my mind to it yeah it was youre welcome bye\",\n          \"okay bout california yeah big broad theres lot lot job opportunities states pretty much big theres lot traffic maybe violence rate bad news even though wanna know whats going environment still watch look see whats going daily basis sociology two year degree liberal arts major sociology im mta bus operator since metro steady growing dream job move company im start classes supervisory next week cause look promote within company thats good thing theres lot opportunities metro take classes theyll pay tuition things nature thanks hard right easy take advantage right cause look promote within since im already working thats good thing good go ahead take classes need youre interested go ahead move ladder soon possible mean im sorry okay read take long walk hot bath meditate close eyes sometimes im pretty much good see bus operator run circumstances situations gotta remain calm still remain professional time look goes mean comes experience something continuous basis usually somewhere line become good look ive driving years dealing public handle circumstances treat people wanna treated im pretty good maybe younger get older get wiser learn different things im still learning today would say family kids even though lot deaths around thats go thats part life experience born gotta leave one day kids keep sane love family thank setting good examples youre first teacher wanna set positive good example kids think thats good thing starts home first teacher kids youre youre one see daily basis wake whatevers taught home lookin learning every day whether home school people kids tendency things see mean try keep positive teach em good morals values get along people regardless race different things nature four half year old son seven year old daughter also twenty three year old yeah im bout daughters pregnant boy three little girls three grandkids one way boy time yeah thank hardest thing right im single parent makes hard alone expensive times depends persons situation whether help job things nature help situation better hard try keep job keep food house maintain support kids best way kids period whats memorable im one family degree kinda yeah kinda even though im baby ten kids ive always kept back mind even though everybody pretty much whole family decent job im one degree kinda gave pat back thats thing remember graduating family support thank happy accomplished something even though may much better high school diploma working bachelors degree ended bad car accident never went back got distracted working time moreso needed income schooling time young parent cause daughter seventeen needed money support never went back feel never late feel ill take classes im metro help move ladder thats im starting class next week thank hm advice wouldve gave wouldnt young mother young age wouldve stayed school let accident distract wouldve remained school wouldnt kids early rather wouldve stayed school part time job something feel education excellent thing person knowledge learning different things keeping mind open learning new ideas every day think thats plus anybodys shoes better selves education maybe maybe promote within company whatever case may help better career im quite sure learn mistakes time dont continue make ones feel okay make mistake long something change even though im going school late still im going wanna better career wise yes oldest daughter argument life shes living right things shes going told needed make changes better situation got argument kids sometimes dont wanna hear hear stuff youre saying even though true dont wanna hear may going something dont wanna hear got argument happened told im im sorry close close situation daughters needs make changes better life ill telling shes shes kinda stubborn way raised listen mom moms gonna tell nothing wrong ive telling years different things kinda talking wall opposite shes regretting cause shes mom told mom im opposite guess gotta bump head couple times get kinda done told done left alone make change frustrating im talking wall shes hearing im seem taking forever change left individual whenever theyre ready mean person get tired something theyll make change may want happen ball court much wow days since two little ones kinda trained go bed eight clock gotta go school think important good nights rest kinda kinda gets ready next day gonna feel rested type person youll day cause everybody days whether theyre good bad thats part life feel good nights good good nights rest hopefully youll good day pretty much need rest im driving bus dealing people job stressful feel im rested itll help irritated tired lazy feel wanna lay go sleep get rest need never thought cause said everybody moments never thought hm dont really best friend person deal used work would tell im outgoing go getter dependable responsible im people person get along others im kinda leave good good mark whether know youd say seems nice young lady whatever something thank try stay happy id rather happy sad kids keep going mean especially go pick school hey mom kinda make day run happy excited mean thank youre welcome good day goodbye\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zz1PO0GesuiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ZnUIrhccDm",
        "outputId": "ca054264-fbf6-49f4-9bb0-cc9d32d61fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"allenai/longformer-base-4096\"\n",
        "model = LongformerModel.from_pretrained(model_name, output_attentions=True, output_hidden_states=True)\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
        "\n",
        "text = \"The Longformer model is designed for handling long documents efficiently.\"\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=\"max_length\", max_length=50)\n",
        "\n",
        "global_attention_mask = torch.zeros_like(inputs['input_ids'])\n",
        "global_attention_mask[:, 0] = 1  # Set the first token to have global attention\n",
        "outputs = model(**inputs, global_attention_mask=global_attention_mask)\n",
        "hidden_states = outputs.hidden_states  # Hidden states for each layer\n",
        "attention_scores = outputs.attentions  # Attention scores for each layer\n",
        "avg_attention_scores = np.mean([att.detach().numpy() for att in attention_scores], axis=(0, 1))\n",
        "token_attention = avg_attention_scores[0]  # Shape: (sequence_length, sequence_length)\n",
        "cls_attention_weights = token_attention[0, :]  # Shape: (sequence_length,)\n",
        "last_hidden_states = hidden_states[-1]\n",
        "word_embeddings = last_hidden_states[0]  # Shape: (sequence_length, hidden_size\n",
        "x = torch.from_numpy(cls_attention_weights[:, None])\n",
        "print(x.shape)\n",
        "print(word_embeddings.shape)\n",
        "sentence_representation = torch.sum( x* word_embeddings, dim=0)\n",
        "\n",
        "print(\"Sentence Representation Shape:\", sentence_representation.shape)\n",
        "print(\"Sentence Representation:\", sentence_representation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4w44N7XchDX",
        "outputId": "62d03a6b-fa77-4fc8-aeca-e659b8127f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([514, 1])\n",
            "torch.Size([50, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnenGop1FtXa",
        "outputId": "884a0d7b-6aa3-4b18-c20a-9f428fcfc916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "# Replace with the path to your dataset\n",
        "dataset = pd.read_csv('/content/final_dataset.csv')\n",
        "class_0 = dataset[dataset[\"class_value\"] == 0]\n",
        "class_1 = dataset[dataset[\"class_value\"] == 1]\n",
        "\n",
        "# Downsample class 0\n",
        "class_0_downsampled = class_0.sample(n=74, random_state=42)\n",
        "\n",
        "# Concatenate\n",
        "balanced_data = pd.concat([class_0_downsampled, class_1], axis=0)\n",
        "balanced_data = balanced_data.rename(columns={\"class_value\": \"label\", \"concatenated_text\": \"text\"})\n",
        "\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"\\nBalanced class distribution:\")\n",
        "print(balanced_data[\"label\"].value_counts())\n",
        "\n",
        "# Split the dataset into training and validation datasets\n",
        "# Adjust this according to your dataset\n",
        "train_size = int(0.8 * len(balanced_data))  # 80% for training\n",
        "val_size = len(balanced_data) - train_size  # 20% for validation\n",
        "train_dataset = balanced_data[:train_size]\n",
        "val_dataset = balanced_data[train_size:]\n",
        "\n",
        "# Load the Longformer tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Tokenize the text data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['concatenated_text'], truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Convert the train and validation data into datasets compatible with Trainer\n",
        "def prepare_dataset(data):\n",
        "    tokenized_inputs = data.apply(tokenize_function, axis=1)\n",
        "    input_ids = [x['input_ids'] for x in tokenized_inputs]\n",
        "    attention_mask = [x['attention_mask'] for x in tokenized_inputs]\n",
        "    labels = data['class_value'].tolist()\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    })\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset)\n",
        "val_dataset = prepare_dataset(val_dataset)\n",
        "\n",
        "# Combine the datasets into a DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset\n",
        "})\n",
        "\n",
        "# Initialize the Longformer model for sequence classification\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "model.gradient_checkpointing_enable()  # Enable gradient checkpointing to save memory\n",
        "\n",
        "# Define the training arguments (batch size of 1 to avoid OOM)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,  # Use batch size of 1 to avoid OOM\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate a larger batch size\n",
        "    fp16=True,  # Enable mixed precision to reduce memory usage\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\",  # Disable wandb logging\n",
        ")\n",
        "\n",
        "# Define evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "# Define the Trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_dict['train'],  # Pass the properly formatted training dataset\n",
        "    eval_dataset=dataset_dict['validation'],  # Pass the validation dataset\n",
        "    compute_metrics=compute_metrics,  # Include the evaluation metrics\n",
        ")\n",
        "\n",
        "# Free up any GPU memory before starting training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Start the fine-tuning process\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./fine_tuned_longformer')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "h6DjzJi1Jlx3",
        "outputId": "152d6807-c544-4946-c1b0-8e248ecb80b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Balanced class distribution:\n",
            "label\n",
            "1    74\n",
            "0    74\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'concatenated_text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'concatenated_text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bf93d7e730b7>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     })\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bf93d7e730b7>\u001b[0m in \u001b[0;36mprepare_dataset\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Convert the train and validation data into datasets compatible with Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtokenized_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bf93d7e730b7>\u001b[0m in \u001b[0;36mtokenize_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Tokenize the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concatenated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Convert the train and validation data into datasets compatible with Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'concatenated_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "# Replace with the path to your dataset\n",
        "dataset = pd.read_csv('/content/final_processed_transcripts.csv')\n",
        "\n",
        "# Load the Longformer tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Tokenize the text data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Apply tokenization to the 'processed_text' column\n",
        "tokenized_inputs = dataset['processed_text'].apply(tokenize_function)\n",
        "\n",
        "# Convert the tokenized inputs and labels into a format compatible with Trainer\n",
        "# Dataset expects input_ids, attention_mask, and labels\n",
        "input_ids = torch.tensor([x['input_ids'] for x in tokenized_inputs])\n",
        "attention_mask = torch.tensor([x['attention_mask'] for x in tokenized_inputs])\n",
        "labels = torch.tensor(dataset['class_value'].values)\n",
        "\n",
        "# Create a Dataset object compatible with the Trainer\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': input_ids,\n",
        "    'attention_mask': attention_mask,\n",
        "    'labels': labels\n",
        "})\n",
        "\n",
        "# Initialize the Longformer model for sequence classification\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "model.gradient_checkpointing_enable()  # Enable gradient checkpointing to save memory\n",
        "\n",
        "# Define the training arguments (batch size of 1 to avoid OOM)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,  # Use batch size of 1 to avoid OOM\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate a larger batch size\n",
        "    fp16=True,  # Enable mixed precision to reduce memory usage\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\",  # Disable wandb logging\n",
        ")\n",
        "\n",
        "# Define the Trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # Pass the properly formatted dataset\n",
        ")\n",
        "\n",
        "# Free up any GPU memory before starting training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Start the fine-tuning process\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./fine_tuned_longformer')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer')\n"
      ],
      "metadata": {
        "id": "rX5pIctwgh6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "ce181d7b-7811-4f44-87df-385f8cdd569e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "Initializing global attention on CLS token...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [66/66 07:00, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.702500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.664600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.645900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.701100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.652000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_longformer/tokenizer_config.json',\n",
              " './fine_tuned_longformer/special_tokens_map.json',\n",
              " './fine_tuned_longformer/vocab.json',\n",
              " './fine_tuned_longformer/merges.txt',\n",
              " './fine_tuned_longformer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "# Replace with the path to your dataset\n",
        "dataset = pd.read_csv('/content/final_dataset.csv')\n",
        "\n",
        "# Split dataset into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the Longformer tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['concatenated_text'], truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Apply tokenization\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format to PyTorch tensors\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'class_value'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'class_value'])\n",
        "\n",
        "# Rename class_value to labels as expected by the model\n",
        "train_dataset = train_dataset.rename_column(\"class_value\", \"labels\")\n",
        "test_dataset = test_dataset.rename_column(\"class_value\", \"labels\")\n",
        "\n",
        "# Calculate class weights based on the class distribution in the training data\n",
        "class_counts = train_df['class_value'].value_counts().to_dict()\n",
        "total_samples = len(train_df)\n",
        "class_weights = {label: total_samples/count for label, count in class_counts.items()}\n",
        "class_weights_tensor = torch.tensor([class_weights[0], class_weights[1]]).cuda()\n",
        "\n",
        "# Initialize the Longformer model for sequence classification\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "model.gradient_checkpointing_enable()  # Enable gradient checkpointing to save memory\n",
        "\n",
        "# Custom loss function with class weights\n",
        "loss_fn = CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Custom Trainer class to compute weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss = loss_fn(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define training arguments with learning rate scheduling\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,  # Use batch size of 1 to avoid OOM\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate larger batch size\n",
        "    fp16=True,  # Enable mixed precision to reduce memory usage\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,  # Load the best model based on validation\n",
        "    report_to=\"none\",  # Disable wandb logging\n",
        "    lr_scheduler_type=\"linear\",  # Linear learning rate scheduling\n",
        "    warmup_steps=500  # Number of warmup steps\n",
        ")\n",
        "\n",
        "# Define the custom Trainer object\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # Train dataset\n",
        "    eval_dataset=test_dataset,  # Validation dataset\n",
        ")\n",
        "\n",
        "# Free up any GPU memory before starting training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Start the fine-tuning process\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./fine_tuned_longformer')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer')\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n"
      ],
      "metadata": {
        "id": "mFEpcMq6KEGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "337cba1f02d14a06b2eacc6306f4b89c",
            "0cf8751042434350aff5250dbf3a8f30",
            "650b212b33ea4e519ebcd2f4a193b9fa",
            "5326c6f8a43f4c67a4b2af48fa49136d",
            "eed53f9027e54e49b3afe17eca6ea1c9",
            "aab73900546f4cb9a56ac20e7814de61",
            "788eb8c8d5ee4a8ab5996658d59d60a2",
            "9805e28d86364ce49fb350e314bd5220",
            "5c2d15e641c74068b5d51a5d1f8a038c",
            "420fe4b85f6d4cd2a94cc31973e532d7",
            "e46b012244b749f5acdf84931de58620",
            "5da554930c624662a77195ae89297811",
            "9a77e43fb97d4d96abc0b7e399164043",
            "8b962e66887844a8adc94e7351448085",
            "a28ccb515ca94d6fa99d087dd588609c",
            "55ce186257ec4fd182488ccd0163528c",
            "99d7a38bc4d346ecbe5d09e19dc76b0b",
            "8629a6a692d742939c5deff35771f5aa",
            "97d1136188a24beaa003b9e600814912",
            "01685a81b6a74c18bdcbb4652214a207",
            "951bd8aa7c4f453b817efaab88973f49",
            "8c0e8ac2f4f14939a14ed456d8b5ba00",
            "805c74c0f7d4417b9c2903323e05fe92",
            "aa74d81c72b54e2fb46295226a391bf7",
            "90a25952240e42279de9315e1c1681f5",
            "8851487c4afd42d899322845d683c8f3",
            "cf8a1329f07e44fbb1afc5ee838e8107",
            "b1785aa906524ba49ffdf62e01d8ddc0",
            "a87d7e703d1d444c9b53c830ad5e5bb3",
            "85704ff983d84ba394b561736d8475db",
            "0b016f9163df41f9bf85449cf2893540",
            "3c63bcf6600d43b4a2e838f0cb60ffe1",
            "d4adebefa3b34b93b8a8a342f67861f1"
          ]
        },
        "outputId": "96a002de-2236-456f-b1ee-4f524098d64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "337cba1f02d14a06b2eacc6306f4b89c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5da554930c624662a77195ae89297811"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Initializing global attention on CLS token...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/597M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "805c74c0f7d4417b9c2903323e05fe92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 09:09, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>0.697623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.687400</td>\n",
              "      <td>0.724433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.643000</td>\n",
              "      <td>0.788727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.602300</td>\n",
              "      <td>0.827833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.6976227760314941, 'eval_runtime': 5.4136, 'eval_samples_per_second': 7.019, 'eval_steps_per_second': 0.924, 'epoch': 4.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "# Replace with the path to your dataset\n",
        "dataset = pd.read_csv('/content/final_dataset.csv')\n",
        "\n",
        "# Split dataset into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the Longformer tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['concatenated_text'], truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Apply tokenization\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format to PyTorch tensors\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'class_value'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'class_value'])\n",
        "\n",
        "# Rename class_value to labels as expected by the model\n",
        "train_dataset = train_dataset.rename_column(\"class_value\", \"labels\")\n",
        "test_dataset = test_dataset.rename_column(\"class_value\", \"labels\")\n",
        "\n",
        "# Calculate class weights based on the class distribution in the training data\n",
        "class_counts = train_df['class_value'].value_counts().to_dict()\n",
        "total_samples = len(train_df)\n",
        "class_weights = {label: total_samples/count for label, count in class_counts.items()}\n",
        "class_weights_tensor = torch.tensor([class_weights[0], class_weights[1]]).cuda()\n",
        "\n",
        "# Initialize the Longformer model for sequence classification\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "model.gradient_checkpointing_enable()  # Enable gradient checkpointing to save memory\n",
        "\n",
        "# Custom loss function with class weights\n",
        "loss_fn = CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Custom Trainer class to compute weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss = loss_fn(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    labels = labels.numpy() if isinstance(labels, torch.Tensor) else labels\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "# Define training arguments with learning rate scheduling\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,  # Use batch size of 1 to avoid OOM\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients to simulate larger batch size\n",
        "    fp16=True,  # Enable mixed precision to reduce memory usage\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,  # Load the best model based on validation\n",
        "    report_to=\"none\",  # Disable wandb logging\n",
        "    lr_scheduler_type=\"linear\",  # Linear learning rate scheduling\n",
        "    warmup_steps=500  # Number of warmup steps\n",
        ")\n",
        "\n",
        "# Define the custom Trainer object\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # Train dataset\n",
        "    eval_dataset=test_dataset,  # Validation dataset\n",
        "    compute_metrics=compute_metrics,  # Evaluation metrics\n",
        ")\n",
        "\n",
        "# Free up any GPU memory before starting training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Start the fine-tuning process\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./fine_tuned_longformer')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "eval_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test Set Evaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686,
          "referenced_widgets": [
            "6829be31b6d9464b8da691240851a8e7",
            "d8a1879739c44c9da0ad81e63dfe096e",
            "652e3eaebc3e46458eeec023c02382dd",
            "1b3c9fe7896b48d9a8d6343f92e3a7ea",
            "7499c8699e7546958d841101f1af5bca",
            "f43a78a71c904b98add9f4e59cafde41",
            "21558656beb04d86ae73125a6dd4ace7",
            "1809c8e7ec8a4c7bb8a70832e015e48d",
            "a4061f2f991e4fd2b7f9fa0fdb8086b4",
            "c72d1c04d5e54263b490c0bb6889f533",
            "06b60efa83744a44ae51e1e02b4373ef",
            "49dd2aab32b740cbac9a5f54e0ab62cf",
            "bce9ce386d0c414aa216476c8feb0a38",
            "e61f53f6f10647d8899e841e6e43aa49",
            "b31ef8d59caa400aaae3adf2c63c57b1",
            "5aa715f73ab04ca3bbb2f4f06b55a72b",
            "e792ee195d9546dda74f731131b37d48",
            "2899e5828a99454287c86e542253d03d",
            "046e677a80a0430bad2a1bc74b2991bb",
            "f793a99cc5b04c26bb448cc78e2e126c",
            "cff0c6f1cdd9469bb5da9fdccfe60ced",
            "bfc71edac85845f392727318cc8a99f0"
          ]
        },
        "id": "fjjbMcKSQLii",
        "outputId": "b9f35cdb-3227-466b-fb3e-4bb68a7953c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6829be31b6d9464b8da691240851a8e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49dd2aab32b740cbac9a5f54e0ab62cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 09:07, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.690400</td>\n",
              "      <td>0.703083</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.697700</td>\n",
              "      <td>0.720880</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.654100</td>\n",
              "      <td>0.765761</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>0.848619</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation Results:\n",
            "eval_loss: 0.7031\n",
            "eval_accuracy: 0.3684\n",
            "eval_precision: 0.2500\n",
            "eval_recall: 0.1000\n",
            "eval_f1: 0.1429\n",
            "eval_runtime: 5.2264\n",
            "eval_samples_per_second: 7.2710\n",
            "eval_steps_per_second: 0.9570\n",
            "epoch: 4.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['concatenated_text'][183]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "P0ot9w5Wiaf1",
        "outputId": "3ebed2f7-5caa-436b-ce53-e209720d836d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, I’m fine, thank you. I’m from San Fernando Valley, having moved from Detroit, Michigan, where I was born and raised. I relocated to LA in 2007, and unlike Detroit’s colder climate, I enjoy the warmer, more open environment here. Since my husband and I separated, I’ve found the cultural scene in LA, like museums and various activities, more aligned with my interests. I appreciate the outdoors and recall a memorable camping trip to Death Valley with friends during college. Professionally, I shifted from journalism to philosophy, intrigued by its diverse applications, and now I envision a career possibly involving child behavior studies. I manage my temperament well, often turning to music, TV, and walks to unwind. The biggest challenges I’ve faced include debating financial issues with my ex-husband and managing family dynamics, particularly during emotional discussions. A significant life decision was handling a friend’s serious illness, balancing advice with personal judgment. My relationship with my family, especially my siblings, has evolved, improving as we’ve grown older, although we’ve had our disputes. One of my philosophy professors significantly influenced my academic path, igniting my passion for the subject. Sleep is generally easy for me, though mornings can be tough. Recently, attending a department party with my boyfriend lifted my spirits, as I enjoyed socializing and meeting new people. If I could change one thing about myself, it would be my organizational skills, which sometimes lead to procrastination. Reflecting on my past, I wish I had been gentler with myself and others during my youth, recognizing that personal growth and understanding come with time.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
        "\n",
        "# Load the fine-tuned Longformer model with safetensors format\n",
        "model = LongformerForSequenceClassification.from_pretrained('/content/fine_tuned_model')\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('/content/fine_tuned_model')\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to predict the class for a new text input\n",
        "def predict(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "    # Disable gradient calculations (important for evaluation mode)\n",
        "    with torch.no_grad():\n",
        "        # Get model outputs\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "        # Get predicted class (index of max probability)\n",
        "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    return predicted_class, probabilities\n",
        "\n",
        "# Example usage: Test with new data\n",
        "# new_text = \"okay how bout yourself here in yeah that its big and broad theres a lot to do a lot of job opportunities than other states pretty much that its big and theres a lot you can do here traffic maybe the violence rate bad news even though you wanna know whats going on in your environment but you still have to watch it you can look out to see whats going on on a daily basis sociology i have a two year degree in liberal arts but my major was sociology no im an mta bus operator since metro is steady growing my dream job is to move up in the company and im about to start some classes for supervisory next week cause they look to promote within the company thats the good thing theres a lot of opportunities at metro where you can take classes and theyll pay for your tuition and things of that nature thanks its not hard as right now its easy if you take advantage of it right now cause they look to promote within since im already working there thats a good thing its good to go ahead and take the classes that you need that youre interested in and go ahead and move up the ladder as soon as possible what do you mean im sorry okay read take a long walk hot bath meditate just close my eyes sometimes im pretty much good because see by me being a bus operator you run into circumstances and situations you gotta remain calm and still remain professional at the same time i look at it it it goes with i mean it comes with experience you do something on a continuous basis usually you some somewhere down the line you become good at it i i look at it that ive been driving for years and dealing with the public its just how you handle circumstances you treat people you wanna be treated no im pretty good at it now maybe when i was younger you as you get older you get wiser you learn different things and im still learning today i would say my family my kids even though i had been having a lot of deaths around me but thats just go thats part of the life experience you born here but you gotta leave here one day but my kids will keep me sane and i love them and my family no setting good examples because youre the first teacher and you wanna set a positive good example for your kids and i think thats a good thing and it starts at home by you being the first teacher your kids youre youre their one that they see on a daily basis when they wake up whatevers been taught in the home they lookin and learning every day whether its a home school people kids have a tendency to do things what they see what i mean you try to keep it positive teach em good morals and values and how to get along with other people regardless of race and different things of that nature i have a four and a half year old son i have a seven year old daughter and i also have a twenty three year old yeah im bout to be my daughters pregnant with a boy she has three little girls i have three grandkids and one on the way which is a boy this time yeah the hardest thing is right now im a single parent that makes it hard alone itself and they can be expensive at times it depends on the persons situation the whether they have help or a job things of that nature to help the situation better but its hard but you i try to keep a job keep food in the house just maintain and support my kids the best way i can with my kids or just period whats memorable for me is that im the only one in my family with a degree its kinda yeah its kinda even though im the baby of ten kids and ive always kept that in the back of my mind even though everybody pretty much my whole family have decent job but im the only one with a degree i kinda gave myself a pat on the back i just thats the only thing i remember graduating and my family there and to support me happy that i accomplished something just even though it may not be much but it was better than just have having a high school diploma and i had i was working on my bachelors degree but i ended up in a bad car accident i never went back i got distracted and i was working at the same time but i was just moreso i needed income than than schooling at that time because i was a young parent cause i had my daughter at seventeen i was i needed the money to support her but i never went back but i feel its never too late i feel ill take some classes now that im with metro to help me move up the ladder thats why im starting a class next week hm the advice i wouldve gave myself that i wouldnt have been a young mother at a young age and that i wouldve stayed in school not let the accident just distract me and not i wouldve remained in school i wouldnt have had kids early rather i wouldve stayed in school and have a part time job or something just i just feel education is a excellent thing for a person just having knowledge and learning different things keeping your mind open to learning new ideas every day i think thats a plus in anybodys shoes just to better they selves through education maybe to maybe promote within your company or whatever the case may be that they help better your career im not quite sure you learn from your mistakes but at the same time you dont continue to make the same ones i feel its okay to make a mistake but long as you do something to change myself even though im going to school late but still im going i wanna better myself career wise yes my oldest daughter we had a argument because just the life that shes living right now and the things that shes going through and i had told her that she just needed to make some changes to better her situation and we got into an argument because how your kids sometimes dont wanna hear it hear the stuff that youre saying even though its true or or they just they just dont wanna hear it they may be going through something they dont wanna hear but we got into a argument about it but that just happened i just told her im not im sorry very close very close its just that the the situation my daughters in she just needs to make some changes to better her her life and ill be telling shes shes kinda stubborn in her own way i was raised to listen to your mom your moms not gonna tell you nothing wrong and ive been telling her over the years different things and its its kinda i was talking to a wall because she she did the opposite and now shes she regretting it cause shes my mom told me this mom im doing the opposite i guess she gotta bump her head a couple of times to get it its kinda i done told you i done left it alone and now its up to you to make the change its very frustrating because its im talking to a wall and shes not hearing me and im it seem its taking forever for her to change but its left up to the individual whenever theyre ready what i mean once the person get tired of something theyll make it change it may not be when you want it to happen but the ball is her court i only can do much wow i have my days since i have two little ones i kinda trained them to go to bed at eight o clock because they gotta go to school and i think its important to have a good nights rest because it kinda it it kinda gets you ready for the next day or how you gonna feel if you rested what type of person youll be that day cause everybody have they days whether theyre good or bad but thats just a part of life and i feel if you had a good nights good good nights rest hopefully youll have a good day pretty much i need my rest because im out there driving that bus and dealing with all these people and the job itself if very stressful i feel if im rested itll help me what am i irritated tired lazy feel i wanna lay down go to sleep get the rest that i need but i never thought about that i just cause i said everybody have their moments they do i never thought about that hm no no i dont really have a best friend but a person that i deal with and i used to work with she would tell you that im very outgoing a go getter dependable responsible im a people person i get along with others im kinda i leave a good a a good mark whether i know you or not if you was to you and i now i youd say she seems a nice young lady or whatever something that i try to stay happy id rather be happy than sad my kids keep me going what i mean especially when i go to pick them up from school or their being hey mom that just kinda make my day just them run up to me and be happy and excited what i mean youre more than you have a good day goodbye\n",
        "# \"\n",
        "new_text = \"I am feeling very down, I cant think straight. I am constantly stressed\"\n",
        "predicted_class, probabilities = predict(new_text)\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Class Probabilities: {probabilities}\")\n"
      ],
      "metadata": {
        "id": "cF9UjebzUpRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58745451-23de-430b-c9d1-b4b70e8a1544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 0\n",
            "Class Probabilities: [[0.5211971  0.47880286]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALjeceDuLcxK",
        "outputId": "e831f3e4-0796-457c-e9dc-0fcc479e7505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/final_processed_transcripts.csv')\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWfjusaNZJFI",
        "outputId": "73135d11-89a7-421a-a537-762bd8449c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['number', 'class_value', 'processed_text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class_value'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "wWzkS9whZR0i",
        "outputId": "46579ffe-44d1-4c45-fba0-6ce60e19b296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class_value\n",
              "0    116\n",
              "1     65\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_value</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vW0QKdfyZWcG",
        "outputId": "a8956ffd-8e67-4658-aa00-73b000c6bd2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   number  class_value                                     processed_text\n",
              "0     300            1  good my parents are from here i love it i the ...\n",
              "1     301            1  k im doing good im from great i live in west t...\n",
              "2     302            0  im fine how about yourself im from what part o...\n",
              "3     303            0  okay how bout yourself here in yeah that its b...\n",
              "4     304            0  im doing good from the cool weather the beache..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93024bea-68ba-4b96-afc9-fa1fb9db0109\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>class_value</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>good my parents are from here i love it i the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>301</td>\n",
              "      <td>1</td>\n",
              "      <td>k im doing good im from great i live in west t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302</td>\n",
              "      <td>0</td>\n",
              "      <td>im fine how about yourself im from what part o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "      <td>okay how bout yourself here in yeah that its b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>304</td>\n",
              "      <td>0</td>\n",
              "      <td>im doing good from the cool weather the beache...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93024bea-68ba-4b96-afc9-fa1fb9db0109')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93024bea-68ba-4b96-afc9-fa1fb9db0109 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93024bea-68ba-4b96-afc9-fa1fb9db0109');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-288d738e-2938-4d2d-8114-0262986f2fc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-288d738e-2938-4d2d-8114-0262986f2fc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-288d738e-2938-4d2d-8114-0262986f2fc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 181,\n  \"fields\": [\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53,\n        \"min\": 300,\n        \"max\": 484,\n        \"num_unique_values\": 181,\n        \"samples\": [\n          319,\n          343,\n          456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 181,\n        \"samples\": [\n          \"sure mm okay thats a good question i the familiarity with everything i know where everything is in the city mm thats all i can say right now spread out hard to get places is there anything else my dream job i dont think there is a dream job for me no there isnt one mm im unemployed right now am i mm thats true i started i studied urban planning i think this school shooting thing and the nra seeming to not wanna budge on this gun control issue thing thats it mm i try to remove myself from that situation thats annoying me ive gotten better over the years most of the time i just try to walk away or control my emotions in terms of just walking away mm just watch tv now i would say my children being born i have four children each birth was speical and it was a unique experience each time its a lot easier now because theyre all adults but it was challenging i would say seeing your children grow up to be successful and exceeding your expectations you worry all the time you worry for em now im not around them as much and i certainly worry about em that i saw my children about a week ago im usually pretty happy when i see em i have interest yeah mm my girlfriend and insignificant no around la maybe but thats about it why dont i travel i dont have the funds to do that anymore or the health no no yes mm id say about a year recognizing that there were some things in me that that were wrong i knew that there was something wrong cause i wasnt myself i was always tired and not excited about things anymore and kinda lethargic laying around and just not feeling myself mm about the same yes i do once a month yeah i do i do its its i see a psychologist and we talk about things i dont really wanna elaborate in detail but its it i seem to think that its helpful i i think thats a hard question lets move on please irritable cranky yeah it is ooh thats a good question its been awhile id say year and a half maybe theres been a lot going on in my life i just lost my parent my dad my last parent just a lot of stuff going on ill leave it at that i still sports and watching a good game or something is usually puts me in a good mood particularly if my team wins i usc i have a nephew thats freshman football player at usc and ive been a trojan football fan for forty years yeah i i think i i listen and im pretty much honest and straightforward thats a good question i dont know you would have to ask her definitely my mother but shes deceased now shes been deceased ten years but she was definitely positive influence my entire life no i have many regrets too many to name and number but its you have the the benefit of hindsight and yeah i have a lot of regrets to listen to the older people in my life the people who cared about me the people who only interest was to guide me in the right direction i said my kids im very proud of em sure my pleasure\",\n          \"yes im okay yes i the weather i the people different things to do out here mm im not really sure that get xxx i would have to say someone being rude or someone bullying or just somebody that has a negative attitude when im annoyed it all depends i might make have a comment or something that or i might just absorb it or something just think about it it all depends on the situation no i dont i think i had a disagreement i dont know when the last time ive been in some argument i really dont its been a long time it was just a disagreement but i i havent argued with anyone someone in quite some time i cant even recall it was a family matter and my brother had a disagreement with with one of our other brothers and he was upset about that in return i got a little upset because what you mean what you mean how hard is what for for laughing now could you go over that again what was the question okay listen to music somewhat i dont know why i guess thats how it is a a little bit i do why did you ask why did you ask me that huh basic things english math but whyd you ask me that question though im trying to find employment right just a job that i enjoy going to i dont really have a dream job no when my kid children was small playing with em thats the last time i was really that i recall its not easy trying to give some guidance or some advice that theyll listen to being a parent you just connected to someone its family someone that you love and someone that loves you isnt much to tell i mean i have children just not children i have one child and two sons thats older theyre adults i think im kinda close with them what do i what what you mean what do i think of todays kids what do you mean by that i think theyre more i dont think theyre as respectful as they were when i was a when i was young when i was a kid i think they got more disrespectful no no before i maybe about six months ago or something that just the way i was feeling i just wasnt feeling good i was feeling sad and wasnt sleeping good and just wasnt feeling right i had a problem with the way i was feeling that was the whole purpose of me going to seek some kinda help feel alright have i ever did what no right now no i dont sleep that good i dont know why if i had an answer if i had an answer i would sleep better i dont know no i never i never been to therapy i dont have a best friend i have a a couple i think i have some good qualities i think im a good person the company of my associates that usually do just hanging out with a friend we were just hanging out laughing talking drinking beer yeah i felt alright no i shouldve completed college i said i should have i got many of em i have a lot of em getting up this morning that was memorable cause it was a new day and thankful to be to be living today mhm man i would say being a father just being a father and that is a a memorable thats a good experience excuse me i dont i cant i had a couple of em i guess some people that i associated with thats the most one i can think of alright\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['processed_text'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "qSvpWNSQZYf1",
        "outputId": "d3c95c7e-72e5-4e77-d242-aaeb53894823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'k im doing good im from great i live in west the west side its alright i xxx no i live alone i love it im from here i grew up here its natural the weather the weather its always good its never its never bad theres always something to do its rarely a dull moment the traffic the traffic is horrible traffic is horrible in almost any major city but i hate the traffic not really i mean i have enough things going on here if i travel its usually somewhere thats within driving distance i studied business i did no ive ive been done for a few years i havent gone to school for a while one of these days ill go back to graduate school but my dream job would be to just work for myself and making lots of money i dont know i dont really have a dream job just something that i can i can work under my own terms and get paid decently and and be in a creative creative environment i dont know i think its just a matter of finding the right situation right now eh its been people are a little conservative about what they want and how they want it its a little tougher than it seems it should be but i dont know i think when the situations right i dont think its too difficult yep i work as an assistant administrative assistant through a temp agency its just i get sent out to do to do desk jobs yes and no i mean i feel i feel i could do more but it works yeah im pretty close i mean theyre around god really mad stupid people just doing just doing anything to annoy me thats thats the big thing just just irritating stupid people who just do things just to provoke provoke me for no reason at all whats a good example just random people who who think its funny to just sit there and get a rise out of me just it doesnt have to be one any specific situation its just people who just think its funny to i think theyre just generally sadistic and they just think its its funny to to just prod you its poking a stick at an angry dog knowing that they know how to they just wanna push your buttons for no reason god i dont remember i with those situations i usually try not to remember when when it happens i just i just let it go and just the past is the past i just tend not to look back what do you mean okay god what do i do to relax i to run i to go to the gym listen to music i have a lot of musician friends i just im usually around musicians anything of that sort i i everything from punk rock art to tattoos to just anything thats thats generally art and creative whos been a positive i think its just friends in general who who seem to who seem to do and i think they theyre very inspiring and which is sometimes a a bit tough in in a town where i think everybodys on the go trying to accomplish their own goals they dont its sometimes hard to find someone whos gonna be uplifting or try to be inspiring i dont really have anybody in particular but people have brought up things here and there just hey instead of instead of doing this how about doing that or hey youre good at this why arent you doing that or something that just im always looking for new opportunities they always point out things that maybe i might i could do differently instead of just being negative saying hey dont do that thats no thats why are you doing that its a waste of time i guess it depends on who you talk to im im okay at it i could work at that i dont know i mean i can i i think i can do better at it back to the point about people provoking me i mean i try not to blow steam and let them get under my skin i just usually try not to let it get to me but i dont know i guess with temper i guess it depends on how i handle my stress lately ive been better at it just because i think my situations been a little bit better no no no nothing major i mean maybe when i was younger i couldve traveled more or i couldve worked towards something that paid better jobwise but i mean those are all things that i think at any point in life you always think i coulda shoulda wouldve done but but then again i think thats natural for anybody i mean i could i couldve become a banker or i couldve become a lawyer or a doctor and made about ten times the money that i make now but but then again i dont the law and i dont medicine im it wasnt meant to be yeah i think i think my in my life i knew that i theres a lot of things i have theres more dislikes than likes i kinda narrowed it down to what am i good at and what am i not good at and what am i gonna work or who who am i gonna work with and who will i not work with i i kinda sorted out and then the list answered itself no it i dont think it was hard but it was just but i think it was a real reality check and i think it its a good thing cause sometimes trying to conform to doing things that doesnt really fit you doesnt make sense its trying to shove a a round peg into a square a square hole and its it just no matter how you try to shove it in its not gonna go in sometimes its just might as go down a path that seems to work better for you memorable experiences i think its just i dont really have any one in particular i think i think every day is almost a memorable experience whether its positive or negative i think its just everything from getting it just just the fact that i got a job and i can i can take care of myself is already almost a memorable experience maybe for the average person it it sounds stupid but i think just the fact that im able im able to get this far in life without completely selfdestructing is already an accomplishment i feel ive gotten somewhere maybe not to not maybe not to the point to the average person they might think why arent you a millionaire but what not everybody can be a millionaire yeah when was the last time i really felt happy i dont know im not really someone whos i dont have any real high highs or low lows i mean i havent hit any lows i mean i i dont know im usually pretty i feel im a level person and im pretty happy every day i feel if i accomplish one thing then im pretty happy i guess to answer the question yesterday i just feel if i if im able to accomplish something then then hey im happy i dont know i dont really have a best friend but i mean i to answer the question generally friends i think they would say that im very pretty outgoing im pretty determined im trying i try to i try to interact as much as possible im always out networking as much as possible i dont know i guess thats what i think they would describe me as okay no problem alright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/final_processed_transcripts.csv')\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['processed_text'], truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_data, eval_data = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset['class_value'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "eval_dataset = Dataset.from_pandas(eval_data)\n",
        "\n",
        "# Tokenize the train and validation datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Convert the dataset into numpy arrays for oversampling\n",
        "X_train = {'input_ids': np.array(train_dataset['input_ids']),\n",
        "           'attention_mask': np.array(train_dataset['attention_mask'])}\n",
        "y_train = np.array(train_dataset['class_value'])\n",
        "\n",
        "# Concatenate input_ids and attention_mask to create a 2D array\n",
        "X_train_combined = np.hstack([X_train['input_ids'], X_train['attention_mask']])\n",
        "\n",
        "# Apply RandomOverSampler to balance the dataset\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train_combined, y_train)\n",
        "\n",
        "# Split the resampled X back into input_ids and attention_mask\n",
        "input_ids_resampled = X_resampled[:, :X_train['input_ids'].shape[1]]  # First part corresponds to input_ids\n",
        "attention_mask_resampled = X_resampled[:, X_train['input_ids'].shape[1]:]  # Second part corresponds to attention_mask\n",
        "\n",
        "# Convert resampled data back into Hugging Face Dataset format\n",
        "# Rename 'class_value' to 'labels' for Trainer compatibility\n",
        "resampled_train_dataset = Dataset.from_dict({\n",
        "    'input_ids': list(input_ids_resampled),\n",
        "    'attention_mask': list(attention_mask_resampled),\n",
        "    'labels': y_resampled  # Use 'labels' instead of 'class_value'\n",
        "})\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',             # Output directory\n",
        "    evaluation_strategy=\"epoch\",        # Evaluate every epoch\n",
        "    num_train_epochs=5,                 # Number of training epochs\n",
        "    per_device_train_batch_size=2,      # Adjust batch size for your GPU memory\n",
        "    per_device_eval_batch_size=2,       # Batch size for evaluation\n",
        "    warmup_steps=500,                   # Warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                  # Weight decay for regularization\n",
        "    logging_dir='./logs',               # Logging directory\n",
        "    logging_steps=10,                   # Log every 10 steps\n",
        "    save_strategy=\"epoch\",              # Save the model after every epoch\n",
        "    load_best_model_at_end=True,        # Load the best model at the end based on evaluation\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                        # The Longformer model\n",
        "    args=training_args,                 # Training arguments\n",
        "    train_dataset=resampled_train_dataset,  # Use the resampled dataset\n",
        "    eval_dataset=eval_dataset,          # Separate evaluation dataset\n",
        "    tokenizer=tokenizer,                # Tokenizer\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained('./fine_tuned_longformer_new')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer_new')\n",
        "\n",
        "# Optional: Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "e6a1f71ab2a044ff86b7c3482fed31b3",
            "6e2cf7ccbfb14b72919bb7a4dc0237d8",
            "4ad7cc6de217450a930d7ad86a965003",
            "efad0fcbeda541efae229e46db5ecd65",
            "e0f20cccbf884060b4c6739a28f079c5",
            "1e9e78d57f6d40af8d8b56a37f7a92a2",
            "41d67257f74a42ebb3e786e155e99ae5",
            "cc140ca5f5dd408b89374bdcc7cd2b78",
            "8424a920e00641479f700199d5a7a81f",
            "30c6697cf0e0410ab5cc9f4e5ef2af00",
            "e57c277e4a6843b1adfcb9c307dd05cd",
            "9837b3b2af5f488e8c765a512498b159",
            "1a21756e81014166a90245fb598fd15a",
            "e58f3d5bf3b540078bfca32e57656fce",
            "7322c4d26fcc4d1fb6eeff847b632664",
            "4c08c6c39e3c4e9d90aa975e89fc4c3e",
            "b191972bf0394ea8b108db42eb0cf5dc",
            "cf82539faf834e0cabb5384a50603355",
            "d2d9fcc22db84bb49f923162ec151f35",
            "6d4a0293e3fd4bd8a336cad287d759be",
            "48dd9caaf0dc415b8ccb48c2eef13506",
            "73f36ba9a5694103b16e227923643de4"
          ]
        },
        "id": "NhjnULyfZgG-",
        "outputId": "77f33d7e-99d3-4b53-9f06-5975c1ee42a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/144 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6a1f71ab2a044ff86b7c3482fed31b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9837b3b2af5f488e8c765a512498b159"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 63.06 MiB is free. Process 2589 has 14.68 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 365.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5975caac03d7>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Fine-tune the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Save the fine-tuned model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0mglobal_attention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m         outputs = self.longformer(\n\u001b[0m\u001b[1;32m   1917\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         )\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1730\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 )\n\u001b[1;32m   1308\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1310\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m     ):\n\u001b[0;32m-> 1237\u001b[0;31m         self_attn_outputs = self.attention(\n\u001b[0m\u001b[1;32m   1238\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     ):\n\u001b[0;32m-> 1173\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m   1174\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mkey_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         attn_scores = self._sliding_chunks_query_key_matmul(\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0mquery_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_sided_attn_window_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36m_sliding_chunks_query_key_matmul\u001b[0;34m(self, query, key, window_overlap)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;31m# convert diagonals into columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         diagonal_chunked_attention_scores = self._pad_and_transpose_last_two_dims(\n\u001b[0m\u001b[1;32m    838\u001b[0m             \u001b[0mdiagonal_chunked_attention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36m_pad_and_transpose_last_two_dims\u001b[0;34m(hidden_states_padded, padding)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pad_and_transpose_last_two_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;34m\"\"\"pads rows and then flips rows and columns\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         hidden_states_padded = nn.functional.pad(\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0mhidden_states_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         )  # padding value is not important because it will be overwritten\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4550\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4551\u001b[0m                 )\n\u001b[0;32m-> 4552\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m \u001b[0;31m# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 63.06 MiB is free. Process 2589 has 14.68 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 365.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWmkg9Srwy9s",
        "outputId": "b18d926c-51fe-4908-e3a7-401ca90915c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dITVhmzsyFc-",
        "outputId": "311962df-77a0-483d-ba94-e1170dc42cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "# Ensure the necessary NLTK data is downloaded\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Synonym replacement function\n",
        "def synonym_replacement(text, n=2):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "\n",
        "    # Find words that have synonyms\n",
        "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
        "    random.shuffle(random_word_list)  # Shuffle to replace random words\n",
        "\n",
        "    # Limit the number of words to replace\n",
        "    num_replacements = min(n, len(random_word_list))\n",
        "\n",
        "    for random_word in random_word_list[:num_replacements]:\n",
        "        synonyms = wordnet.synsets(random_word)\n",
        "        synonym_words = [lemma.name() for lemma in synonyms[0].lemmas() if lemma.name() != random_word]\n",
        "        if synonym_words:\n",
        "            synonym = random.choice(synonym_words)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Function to compute evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Function to augment the minority class using synonym replacement\n",
        "def augment_minority_class(data, augmentation_func, num_augmented_samples=5):\n",
        "    minority_class = data[data['labels'] == 1]  # Select minority class (Depressed)\n",
        "\n",
        "    augmented_texts = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for index, row in minority_class.iterrows():\n",
        "        for _ in range(num_augmented_samples):\n",
        "            augmented_text = augmentation_func(row['processed_text'])\n",
        "            augmented_texts.append(augmented_text)\n",
        "            augmented_labels.append(1)  # Label for augmented text is the same (Depressed)\n",
        "\n",
        "    augmented_data = pd.DataFrame({'processed_text': augmented_texts, 'labels': augmented_labels})\n",
        "\n",
        "    # Combine original data with augmented data\n",
        "    augmented_dataset = pd.concat([data, augmented_data])\n",
        "\n",
        "    return augmented_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/final_processed_transcripts.csv')\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_data, eval_data = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset['class_value'])\n",
        "\n",
        "# Rename 'class_value' to 'labels' for compatibility\n",
        "train_data = train_data.rename(columns={\"class_value\": \"labels\"})\n",
        "eval_data = eval_data.rename(columns={\"class_value\": \"labels\"})\n",
        "\n",
        "# Augment the minority class using synonym replacement\n",
        "train_data_augmented = augment_minority_class(train_data, synonym_replacement, num_augmented_samples=2)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Tokenize the text data (train and validation datasets)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['processed_text'], truncation=True, padding='max_length', max_length=2048)\n",
        "\n",
        "# Tokenize train and validation data\n",
        "train_tokenized = train_data_augmented.apply(lambda x: tokenize_function({'processed_text': x['processed_text']}), axis=1)\n",
        "eval_tokenized = eval_data.apply(lambda x: tokenize_function({'processed_text': x['processed_text']}), axis=1)\n",
        "\n",
        "# Extract input_ids and attention_mask for SMOTE\n",
        "train_input_ids = np.array([token['input_ids'] for token in train_tokenized])\n",
        "train_attention_mask = np.array([token['attention_mask'] for token in train_tokenized])\n",
        "eval_input_ids = np.array([token['input_ids'] for token in eval_tokenized])\n",
        "eval_attention_mask = np.array([token['attention_mask'] for token in eval_tokenized])\n",
        "\n",
        "# Apply SMOTE to input_ids and labels\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(train_input_ids, train_data_augmented['labels'])\n",
        "\n",
        "# Replicate attention_mask for resampled data (using the same mask as the original input)\n",
        "resampled_attention_mask = np.tile(train_attention_mask[0], (X_resampled.shape[0], 1))  # Replicating the original attention mask\n",
        "\n",
        "# Convert the resampled data back to DataFrame, including attention_mask\n",
        "resampled_train_data = pd.DataFrame({\n",
        "    'input_ids': list(X_resampled),\n",
        "    'attention_mask': list(resampled_attention_mask),  # Use the replicated attention mask\n",
        "    'labels': y_resampled\n",
        "})\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "resampled_train_dataset = Dataset.from_pandas(resampled_train_data)\n",
        "eval_dataset = Dataset.from_pandas(pd.DataFrame({\n",
        "    'input_ids': list(eval_input_ids),\n",
        "    'attention_mask': list(eval_attention_mask),\n",
        "    'labels': eval_data['labels']\n",
        "}))\n",
        "\n",
        "# Load the Longformer model\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)\n",
        "\n",
        "# Define training arguments with early stopping and weight decay\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=10,  # Train for more epochs, but use early stopping\n",
        "    per_device_train_batch_size=1,  # Batch size 1 due to memory limits\n",
        "    gradient_accumulation_steps=16,  # Simulate larger batch size\n",
        "    fp16=True,  # Mixed precision for memory efficiency\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    learning_rate=1e-5,  # Lower learning rate\n",
        "    warmup_steps=500,  # Warmup steps\n",
        "    weight_decay=0.01,  # Add weight decay for regularization\n",
        "    save_total_limit=2,  # Save only the 2 best models\n",
        ")\n",
        "\n",
        "# Trainer initialization\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=resampled_train_dataset,  # SMOTE-resampled dataset\n",
        "    eval_dataset=eval_dataset,              # Validation dataset\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained('./fine_tuned_longformer_with_smote_early_stopping')\n",
        "tokenizer.save_pretrained('./fine_tuned_longformer_with_smote_early_stopping')\n"
      ],
      "metadata": {
        "id": "t_2Hq8VldQTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "7ba58345-2bf5-443e-98b1-c6de3ccd023f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [190/190 32:42, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.696800</td>\n",
              "      <td>0.715781</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.682900</td>\n",
              "      <td>0.712020</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.619000</td>\n",
              "      <td>0.720716</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.539600</td>\n",
              "      <td>0.757443</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>0.789122</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.494600</td>\n",
              "      <td>0.814466</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_longformer_with_smote_early_stopping/tokenizer_config.json',\n",
              " './fine_tuned_longformer_with_smote_early_stopping/special_tokens_map.json',\n",
              " './fine_tuned_longformer_with_smote_early_stopping/vocab.json',\n",
              " './fine_tuned_longformer_with_smote_early_stopping/merges.txt',\n",
              " './fine_tuned_longformer_with_smote_early_stopping/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/final_dataset.csv')\n",
        "x = []\n",
        "text = df['concatenated_text']\n",
        "for t in text:\n",
        "  x.append(len(t.split()))"
      ],
      "metadata": {
        "id": "XUMuYkklydj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OBuPns07OwMO",
        "outputId": "881fee5e-0bcc-4f42-dbba-36959759cd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1461"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh4OFSgSOwz7",
        "outputId": "17ac163f-71f3-4ff0-c7dd-40af3c0ea5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Generate the histogram\n",
        "plt.hist(x, bins=10, edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Number of Tokens')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Token Counts')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "CxUVmVAPPmNF",
        "outputId": "a2cfe3b6-fea3-4d7f-8bbd-a3437e29b727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for num in x:\n",
        "  if num > 512:\n",
        "    cnt += 1\n",
        "print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr9ZXqs5P5Ye",
        "outputId": "ce12b825-170d-45f2-8125-a2d042a04486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LENGTH = 512\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", num_labels=2)\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,  # Rank of the adaptation matrices\n",
        "    lora_alpha=16,  # Scaling factor\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\"]  # Target specific layers in the transformer\n",
        "\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/final_dataset.csv'  # Path to the uploaded file\n",
        "data = pd.read_csv(file_path)\n",
        "# Random undersampling to balance classes\n",
        "def undersample(data, target_col, random_state=42):\n",
        "    class_counts = data[target_col].value_counts()\n",
        "    min_count = class_counts.min()\n",
        "\n",
        "    balanced_data = data.groupby(target_col).apply(\n",
        "        lambda x: x.sample(min_count, random_state=random_state)\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "data_balanced = undersample(data, \"class_value\")\n",
        "\n",
        "# Dataset preparation\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    data_balanced[\"concatenated_text\"], data_balanced[\"class_value\"],\n",
        "    test_size=0.2, stratify=data_balanced[\"class_value\"], random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = TextDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, MAX_LENGTH)\n",
        "val_dataset = TextDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, MAX_LENGTH)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * EPOCHS)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# Validation\n",
        "model.eval()\n",
        "all_predictions, all_labels = [], []\n",
        "total, correct = 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "f1 = f1_score(all_labels, all_predictions)\n",
        "precision = precision_score(all_labels, all_predictions)\n",
        "recall = recall_score(all_labels, all_predictions)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eqZQhsqQTuZ",
        "outputId": "889e3feb-8b9a-411f-dd6e-9bc6de7b382f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-2-566c3c1ca433>:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  balanced_data = data.groupby(target_col).apply(\n",
            "Epoch 1:   0%|          | 0/8 [00:00<?, ?it/s]Initializing global attention on CLS token...\n",
            "Epoch 1: 100%|██████████| 8/8 [00:32<00:00,  4.00s/it, loss=0.647]\n",
            "Epoch 2: 100%|██████████| 8/8 [00:29<00:00,  3.65s/it, loss=0.693]\n",
            "Epoch 3: 100%|██████████| 8/8 [00:29<00:00,  3.72s/it, loss=0.668]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.4667\n",
            "F1 Score: 0.0000\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tMAIkZQ3enbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6a1f71ab2a044ff86b7c3482fed31b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e2cf7ccbfb14b72919bb7a4dc0237d8",
              "IPY_MODEL_4ad7cc6de217450a930d7ad86a965003",
              "IPY_MODEL_efad0fcbeda541efae229e46db5ecd65"
            ],
            "layout": "IPY_MODEL_e0f20cccbf884060b4c6739a28f079c5"
          }
        },
        "6e2cf7ccbfb14b72919bb7a4dc0237d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9e78d57f6d40af8d8b56a37f7a92a2",
            "placeholder": "​",
            "style": "IPY_MODEL_41d67257f74a42ebb3e786e155e99ae5",
            "value": "Map: 100%"
          }
        },
        "4ad7cc6de217450a930d7ad86a965003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc140ca5f5dd408b89374bdcc7cd2b78",
            "max": 144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8424a920e00641479f700199d5a7a81f",
            "value": 144
          }
        },
        "efad0fcbeda541efae229e46db5ecd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c6697cf0e0410ab5cc9f4e5ef2af00",
            "placeholder": "​",
            "style": "IPY_MODEL_e57c277e4a6843b1adfcb9c307dd05cd",
            "value": " 144/144 [00:01&lt;00:00, 113.13 examples/s]"
          }
        },
        "e0f20cccbf884060b4c6739a28f079c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9e78d57f6d40af8d8b56a37f7a92a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d67257f74a42ebb3e786e155e99ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc140ca5f5dd408b89374bdcc7cd2b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8424a920e00641479f700199d5a7a81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30c6697cf0e0410ab5cc9f4e5ef2af00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57c277e4a6843b1adfcb9c307dd05cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9837b3b2af5f488e8c765a512498b159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a21756e81014166a90245fb598fd15a",
              "IPY_MODEL_e58f3d5bf3b540078bfca32e57656fce",
              "IPY_MODEL_7322c4d26fcc4d1fb6eeff847b632664"
            ],
            "layout": "IPY_MODEL_4c08c6c39e3c4e9d90aa975e89fc4c3e"
          }
        },
        "1a21756e81014166a90245fb598fd15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b191972bf0394ea8b108db42eb0cf5dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cf82539faf834e0cabb5384a50603355",
            "value": "Map: 100%"
          }
        },
        "e58f3d5bf3b540078bfca32e57656fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d9fcc22db84bb49f923162ec151f35",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d4a0293e3fd4bd8a336cad287d759be",
            "value": 37
          }
        },
        "7322c4d26fcc4d1fb6eeff847b632664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48dd9caaf0dc415b8ccb48c2eef13506",
            "placeholder": "​",
            "style": "IPY_MODEL_73f36ba9a5694103b16e227923643de4",
            "value": " 37/37 [00:00&lt;00:00, 86.15 examples/s]"
          }
        },
        "4c08c6c39e3c4e9d90aa975e89fc4c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b191972bf0394ea8b108db42eb0cf5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf82539faf834e0cabb5384a50603355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2d9fcc22db84bb49f923162ec151f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4a0293e3fd4bd8a336cad287d759be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48dd9caaf0dc415b8ccb48c2eef13506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f36ba9a5694103b16e227923643de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "337cba1f02d14a06b2eacc6306f4b89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cf8751042434350aff5250dbf3a8f30",
              "IPY_MODEL_650b212b33ea4e519ebcd2f4a193b9fa",
              "IPY_MODEL_5326c6f8a43f4c67a4b2af48fa49136d"
            ],
            "layout": "IPY_MODEL_eed53f9027e54e49b3afe17eca6ea1c9"
          }
        },
        "0cf8751042434350aff5250dbf3a8f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab73900546f4cb9a56ac20e7814de61",
            "placeholder": "​",
            "style": "IPY_MODEL_788eb8c8d5ee4a8ab5996658d59d60a2",
            "value": "Map: 100%"
          }
        },
        "650b212b33ea4e519ebcd2f4a193b9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9805e28d86364ce49fb350e314bd5220",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c2d15e641c74068b5d51a5d1f8a038c",
            "value": 150
          }
        },
        "5326c6f8a43f4c67a4b2af48fa49136d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_420fe4b85f6d4cd2a94cc31973e532d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e46b012244b749f5acdf84931de58620",
            "value": " 150/150 [00:01&lt;00:00, 96.78 examples/s]"
          }
        },
        "eed53f9027e54e49b3afe17eca6ea1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab73900546f4cb9a56ac20e7814de61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788eb8c8d5ee4a8ab5996658d59d60a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9805e28d86364ce49fb350e314bd5220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2d15e641c74068b5d51a5d1f8a038c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "420fe4b85f6d4cd2a94cc31973e532d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46b012244b749f5acdf84931de58620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5da554930c624662a77195ae89297811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a77e43fb97d4d96abc0b7e399164043",
              "IPY_MODEL_8b962e66887844a8adc94e7351448085",
              "IPY_MODEL_a28ccb515ca94d6fa99d087dd588609c"
            ],
            "layout": "IPY_MODEL_55ce186257ec4fd182488ccd0163528c"
          }
        },
        "9a77e43fb97d4d96abc0b7e399164043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d7a38bc4d346ecbe5d09e19dc76b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_8629a6a692d742939c5deff35771f5aa",
            "value": "Map: 100%"
          }
        },
        "8b962e66887844a8adc94e7351448085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d1136188a24beaa003b9e600814912",
            "max": 38,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01685a81b6a74c18bdcbb4652214a207",
            "value": 38
          }
        },
        "a28ccb515ca94d6fa99d087dd588609c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_951bd8aa7c4f453b817efaab88973f49",
            "placeholder": "​",
            "style": "IPY_MODEL_8c0e8ac2f4f14939a14ed456d8b5ba00",
            "value": " 38/38 [00:00&lt;00:00, 144.18 examples/s]"
          }
        },
        "55ce186257ec4fd182488ccd0163528c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d7a38bc4d346ecbe5d09e19dc76b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8629a6a692d742939c5deff35771f5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d1136188a24beaa003b9e600814912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01685a81b6a74c18bdcbb4652214a207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "951bd8aa7c4f453b817efaab88973f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0e8ac2f4f14939a14ed456d8b5ba00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "805c74c0f7d4417b9c2903323e05fe92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa74d81c72b54e2fb46295226a391bf7",
              "IPY_MODEL_90a25952240e42279de9315e1c1681f5",
              "IPY_MODEL_8851487c4afd42d899322845d683c8f3"
            ],
            "layout": "IPY_MODEL_cf8a1329f07e44fbb1afc5ee838e8107"
          }
        },
        "aa74d81c72b54e2fb46295226a391bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1785aa906524ba49ffdf62e01d8ddc0",
            "placeholder": "​",
            "style": "IPY_MODEL_a87d7e703d1d444c9b53c830ad5e5bb3",
            "value": "model.safetensors: 100%"
          }
        },
        "90a25952240e42279de9315e1c1681f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85704ff983d84ba394b561736d8475db",
            "max": 597241956,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b016f9163df41f9bf85449cf2893540",
            "value": 597241956
          }
        },
        "8851487c4afd42d899322845d683c8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c63bcf6600d43b4a2e838f0cb60ffe1",
            "placeholder": "​",
            "style": "IPY_MODEL_d4adebefa3b34b93b8a8a342f67861f1",
            "value": " 597M/597M [00:05&lt;00:00, 98.2MB/s]"
          }
        },
        "cf8a1329f07e44fbb1afc5ee838e8107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1785aa906524ba49ffdf62e01d8ddc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87d7e703d1d444c9b53c830ad5e5bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85704ff983d84ba394b561736d8475db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b016f9163df41f9bf85449cf2893540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c63bcf6600d43b4a2e838f0cb60ffe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4adebefa3b34b93b8a8a342f67861f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6829be31b6d9464b8da691240851a8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8a1879739c44c9da0ad81e63dfe096e",
              "IPY_MODEL_652e3eaebc3e46458eeec023c02382dd",
              "IPY_MODEL_1b3c9fe7896b48d9a8d6343f92e3a7ea"
            ],
            "layout": "IPY_MODEL_7499c8699e7546958d841101f1af5bca"
          }
        },
        "d8a1879739c44c9da0ad81e63dfe096e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43a78a71c904b98add9f4e59cafde41",
            "placeholder": "​",
            "style": "IPY_MODEL_21558656beb04d86ae73125a6dd4ace7",
            "value": "Map: 100%"
          }
        },
        "652e3eaebc3e46458eeec023c02382dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1809c8e7ec8a4c7bb8a70832e015e48d",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4061f2f991e4fd2b7f9fa0fdb8086b4",
            "value": 150
          }
        },
        "1b3c9fe7896b48d9a8d6343f92e3a7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72d1c04d5e54263b490c0bb6889f533",
            "placeholder": "​",
            "style": "IPY_MODEL_06b60efa83744a44ae51e1e02b4373ef",
            "value": " 150/150 [00:01&lt;00:00, 116.13 examples/s]"
          }
        },
        "7499c8699e7546958d841101f1af5bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43a78a71c904b98add9f4e59cafde41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21558656beb04d86ae73125a6dd4ace7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1809c8e7ec8a4c7bb8a70832e015e48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4061f2f991e4fd2b7f9fa0fdb8086b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c72d1c04d5e54263b490c0bb6889f533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b60efa83744a44ae51e1e02b4373ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49dd2aab32b740cbac9a5f54e0ab62cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bce9ce386d0c414aa216476c8feb0a38",
              "IPY_MODEL_e61f53f6f10647d8899e841e6e43aa49",
              "IPY_MODEL_b31ef8d59caa400aaae3adf2c63c57b1"
            ],
            "layout": "IPY_MODEL_5aa715f73ab04ca3bbb2f4f06b55a72b"
          }
        },
        "bce9ce386d0c414aa216476c8feb0a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e792ee195d9546dda74f731131b37d48",
            "placeholder": "​",
            "style": "IPY_MODEL_2899e5828a99454287c86e542253d03d",
            "value": "Map: 100%"
          }
        },
        "e61f53f6f10647d8899e841e6e43aa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046e677a80a0430bad2a1bc74b2991bb",
            "max": 38,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f793a99cc5b04c26bb448cc78e2e126c",
            "value": 38
          }
        },
        "b31ef8d59caa400aaae3adf2c63c57b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff0c6f1cdd9469bb5da9fdccfe60ced",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc71edac85845f392727318cc8a99f0",
            "value": " 38/38 [00:00&lt;00:00, 146.12 examples/s]"
          }
        },
        "5aa715f73ab04ca3bbb2f4f06b55a72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e792ee195d9546dda74f731131b37d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2899e5828a99454287c86e542253d03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "046e677a80a0430bad2a1bc74b2991bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f793a99cc5b04c26bb448cc78e2e126c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cff0c6f1cdd9469bb5da9fdccfe60ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc71edac85845f392727318cc8a99f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}