{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "class_value\n",
      "0    114\n",
      "1     74\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced class distribution:\n",
      "label\n",
      "1    74\n",
      "0    74\n",
      "Name: count, dtype: int64\n",
      "Training samples: (118, 2), Test samples: (30, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\final_dataset.csv\")\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"class_value\"].value_counts())\n",
    "\n",
    "class_0 = data[data[\"class_value\"] == 0]\n",
    "class_1 = data[data[\"class_value\"] == 1]\n",
    "\n",
    "# Downsample class 0 \n",
    "class_0_downsampled = class_0.sample(n=74, random_state=42)\n",
    "\n",
    "# Concatenate \n",
    "balanced_data = pd.concat([class_0_downsampled, class_1], axis=0)\n",
    "balanced_data = balanced_data.rename(columns={\"class_value\": \"label\", \"concatenated_text\": \"text\"})\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(balanced_data[\"label\"].value_counts())\n",
    "\n",
    "train_data, eval_data  = train_test_split(balanced_data, stratify=balanced_data[\"label\"],test_size=0.2, random_state=42)\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_data)\n",
    "\n",
    "print(f\"Training samples: {train_data.shape}, Test samples: {eval_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(\"__index_level_0__\")\n",
    "eval_dataset = eval_dataset.remove_columns(\"__index_level_0__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, SetFitTrainer,TrainingArguments\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "# Load a SetFit model from Hugging Face\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Check if the model is loaded correctly\n",
    "print(f\"Loaded model: {model}\")\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1 # Number of epochs to use for contrastive learning\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "# Assuming the text column is named 'text' and the target label column is named 'label'\n",
    "texts = eval_data['concatenated_text'].values\n",
    "true_labels = eval_data['class_value'].values\n",
    "\n",
    "model = SetFitModel.from_pretrained('/content/setfit-finetuned-model')\n",
    "# Make predictions using your model\n",
    "predicted_labels = model.predict(texts)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')  # Use 'weighted' if multi-class\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from setfit import SetFitModel\n",
    "import os\n",
    "\n",
    "def find_optimal_k(embeddings, max_k=10):\n",
    "    wcss = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(embeddings)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # Use kneed to find the elbow point\n",
    "    kn = KneeLocator(range(1, max_k + 1), wcss, curve='convex', direction='decreasing')\n",
    "    optimal_k = kn.knee\n",
    "    \n",
    "    if optimal_k is None:\n",
    "        optimal_k = max_k  # Default to max_k if elbow not found\n",
    "    \n",
    "    # Ensure optimal_k is at least 1 and does not exceed the number of samples\n",
    "    optimal_k = max(1, min(optimal_k, len(embeddings)))\n",
    "    \n",
    "    return optimal_k, wcss\n",
    "\n",
    "def generate_text_prototypes(embeddings, labels, texts, output_dir=\"./prototypes\", max_k=10):\n",
    "    \"\"\"Function to generate the prototypes\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for label in np.unique(labels):\n",
    "        class_embeddings = embeddings[np.array(labels) == label]\n",
    "        class_texts = np.array(texts)[np.array(labels) == label]\n",
    "        \n",
    "        # Find optimal K\n",
    "        optimal_k, wcss = find_optimal_k(class_embeddings, max_k)\n",
    "        \n",
    "        # Plot elbow curve\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, max_k + 1), wcss, marker='o')\n",
    "        plt.xlabel('Number of clusters (K)')\n",
    "        plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "        plt.title(f'Elbow Method for Class {label}')\n",
    "        plt.savefig(f\"{output_dir}/class_{label}_elbow_plot.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Perform K-means with optimal K (setting to 5 to ensure uniformity between both classes)\n",
    "        kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "        kmeans.fit(class_embeddings)\n",
    "        \n",
    "        # Find the closest text to each centroid\n",
    "        closest_texts = []\n",
    "        for centroid in kmeans.cluster_centers_:\n",
    "            distances = np.linalg.norm(class_embeddings - centroid, axis=1)\n",
    "            closest_idx = np.argmin(distances)\n",
    "            closest_texts.append(class_texts[closest_idx])\n",
    "            \n",
    "        # Save prototypes\n",
    "        with open(f\"{output_dir}/class_{label}_prototypes.txt\", \"w\") as f:\n",
    "            for idx, text in enumerate(closest_texts):\n",
    "                f.write(f\"Prototype {idx + 1}:\\n{text}\\n\\n\")\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\final_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "texts = data[\"concatenated_text\"].tolist()\n",
    "labels = data[\"class_value\"].tolist()\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\finetuned_model\")\n",
    "embeddings = model.encode(texts)  # Generate embeddings for all text in the dataset\n",
    "\n",
    "generate_text_prototypes(embeddings, labels, texts, output_dir=\"./prototypes\", max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input text was classified as depressed. It is most similar to the following prototype:\n",
      "\n",
      "\"Hi. Yes, today is a wonderful day, and I am doing absolutely marvelous. I was born in Cleveland, Ohio, and raised in Tucson, Arizona. I moved to Los Angeles when I was sixteen years old. Iâ€™ve only been back to Cleveland once since leaving. Itâ€™s quite different now, a whole new community. Growing up in Cleveland gave me a great sense of community, which I feel is missing in Los Angeles. My grandmother passed away and left property for my father to manage, so we relocated here. Since I was young and naturally good at meeting new people, it wasnâ€™t hard for me to adjust. Moving has never been difficult for me because I love traveling and experiencing new places. Meeting new people always felt like an adventure. One of my fondest memories comes from 1964 when I went to visit my grandmother in Cleveland. While I was there, I had the chance to visit an Indian reservation. Later, I wrote to them because I had to give a school speech about my summer experiences. They sent me a Kachina Indian doll, which would be worth around a quarter of a million dollars today if I still had it. I can be outgoing and sociable when necessary, though I also have a shy side. In college, I initially pursued Computer Science but later switched to Business Administration with a concentration in Marketing and Advertising. I missed interacting with people, which drew me to marketing. Now, I work as a celebrity photographer. While I love my job, establishing relationships and securing well-paying work is still an ongoing process. Recently, Iâ€™ve reconnected with meditation. I meditate twice a day, and it really helps to calm my body and mind. I usually keep my temper in check, though like anyone, I sometimes lose my cool. Just the other day, my daughter and I had an argument over something I said that hurt her feelings. I didnâ€™t mean to, and it upset me to see her hurt. We work closely together since she is a makeup artist and I am a photographer. This can cause some friction, but Iâ€™m incredibly proud of raising her and her sister. Being a parent is never easy, but my daughters are my greatest accomplishments. One of the most difficult moments in my life was a night that changed everything for me, but I prefer not to go into detail about it. Another tough decision I faced was how my husband and I ended our marriage. Looking back, we both could have handled things differently and better. Another critical decision in my life came when I had a stroke while traveling for work. I was on a plane when I suddenly lost sensation on one side of my body. A doctor on the flight told me not to board my connecting flight, and I chose to go to the hospital instead. That decision probably saved my life. I survived the stroke, which the doctors told me was rare, but Iâ€™ve been left with nerve damage in my hand and face. Despite this, Iâ€™m incredibly grateful to still be alive and able to continue my photography career. Iâ€™ve also struggled with depression, which stemmed from injuries I sustained while I was a teacher. I was hit on the head multiple times and knocked unconscious, leading to sleep apnea and serious trouble with sleeping. Therapy would help, but I canâ€™t afford it since I donâ€™t have medical insurance. Navigating the disability system after my stroke has also been very challenging. Despite all the difficulties, I wake up every day feeling grateful. Just being alive and able to continue doing what I love, like photography, brings me happiness. I donâ€™t dwell on regrets; the past is behind me, and I focus on the present moment. My advice to myself is to keep moving forward, no matter what. Iâ€™m especially proud of discovering my creative side as a visual artist, even though I started later in life. Photography has been a therapeutic outlet for me, and Iâ€™m so thankful for the creative talents Iâ€™ve been able to nurture.\"\n",
      "\n",
      "Similarity Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from setfit import SetFitModel\n",
    "label_to_class = {0: \"not depressed\", 1: \"depressed\"}\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\finetuned_model\")  # Replace with your model path\n",
    "\n",
    "def load_prototypes_from_file(label):\n",
    "    \"\"\"Load prototypes for the given label from the corresponding text file.\"\"\"\n",
    "    file_path = f\"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\class_{label}_prototypes.txt\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        prototypes = [line.strip() for line in f if line.strip() and not line.startswith(\"Prototype\")]\n",
    "    return prototypes\n",
    "\n",
    "def classify_and_explain(text):\n",
    "    \"\"\"Classify input text and explain the prediction using the closest prototype.\"\"\"\n",
    "    predicted_label = model.predict([text])[0].item()\n",
    "    class_name = label_to_class[predicted_label]\n",
    "\n",
    "    prototypes = load_prototypes_from_file(predicted_label)\n",
    "    text_embedding = model.encode([text]).reshape(1, -1)\n",
    "\n",
    "    similarities = [\n",
    "        cosine_similarity(text_embedding, model.encode([proto]).reshape(1, -1))[0][0]\n",
    "        for proto in prototypes\n",
    "    ]\n",
    "\n",
    "    closest_prototype_idx = np.argmax(similarities)\n",
    "    closest_prototype = prototypes[closest_prototype_idx]\n",
    "    closest_similarity = similarities[closest_prototype_idx]\n",
    "\n",
    "    explanation = (\n",
    "        f\"The input text was classified as {class_name}. \"\n",
    "        f\"It is most similar to the following prototype:\\n\\n\"\n",
    "        f\"\\\"{closest_prototype}\\\"\\n\\n\"\n",
    "        f\"Similarity Score: {closest_similarity:.2f}\"\n",
    "    )\n",
    "\n",
    "    return predicted_label, closest_prototype, closest_similarity, explanation\n",
    "\n",
    "input_text = \"Yes, I’m doing fine. I’m originally from Indiana, but I moved to LA about ten years ago because I don’t like the cold weather—LA has great weather, the ocean, and lots to do. One of my favorite memories was spending a day on the Catalina Islands for my birthday. I’ve had a lot of changes in my life, like leaving Indiana for good, which felt huge at the time. I’ve been pursuing a career in filmmaking, something I haven’t done yet but really want to, although I can be shy and have trouble trusting people because of my past. When I’m stressed, I watch TV or go to the movies, and I don’t really argue or lose my temper. I try to avoid stress and push people away, which I regret because it makes it hard to form connections. I don’t have a close relationship with my family; we don’t talk much, and I often feel isolated. Sometimes I struggle to sleep, and racing thoughts or stress keep me up, but I try to manage it with music and relaxation. I’ve been feeling down lately, wishing my life had turned out differently, especially when it comes to having friends or a real relationship. I find comfort in playing online games with avatars where people don’t know who I am. My ideal weekend is playing games, going to the movies, or driving somewhere new to explore. If I could go back in time, I’d tell myself to keep a journal and make different choices. I regret how my life turned out and wish I had more stability, but I’m proud of being self-taught and consider myself a genius at figuring things out. Thanks for listening, and have a good day.\"\n",
    "predicted_label, closest_prototype, similarity_score, explanation = classify_and_explain(input_text)\n",
    "\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Prathima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Prathima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "['Yes, I’m doing fine.', 'I’m originally from Indiana, but I moved to LA about ten years ago because I don’t like the cold weather—LA has great weather, the ocean, and lots to do.', 'One of my favorite memories was spending a day on the Catalina Islands for my birthday.', 'I’ve had a lot of changes in my life, like leaving Indiana for good, which felt huge at the time.', 'I’ve been pursuing a career in filmmaking, something I haven’t done yet but really want to, although I can be shy and have trouble trusting people because of my past.', 'When I’m stressed, I watch TV or go to the movies, and I don’t really argue or lose my temper.', 'I try to avoid stress and push people away, which I regret because it makes it hard to form connections.', 'I don’t have a close relationship with my family; we don’t talk much, and I often feel isolated.', 'Sometimes I struggle to sleep, and racing thoughts or stress keep me up, but I try to manage it with music and relaxation.', 'I’ve been feeling down lately, wishing my life had turned out differently, especially when it comes to having friends or a real relationship.', 'I find comfort in playing online games with avatars where people don’t know who I am.', 'My ideal weekend is playing games, going to the movies, or driving somewhere new to explore.', 'If I could go back in time, I’d tell myself to keep a journal and make different choices.', 'I regret how my life turned out and wish I had more stability, but I’m proud of being self-taught and consider myself a genius at figuring things out.', 'Thanks for listening, and have a good day.']\n",
      "tensor([1.5191, 2.6860, 3.0981, 2.4822, 2.2795, 2.9713, 2.6741, 3.3988, 3.3339,\n",
      "        2.1091, 0.7071, 1.6276, 2.1501, 2.7656, 2.2164])\n",
      "The input text was classified as **depressed**.\n",
      "Here are the sentences with their contribution scores:\n",
      "\n",
      "• \"I’ve been pursuing a career in filmmaking, something I haven’t done yet but really want to, although I can be shy and have trouble trusting people because of my past.\" (Adjusted Contribution: 2.45)\n",
      "• \"When I’m stressed, I watch TV or go to the movies, and I don’t really argue or lose my temper.\" (Adjusted Contribution: 3.41)\n",
      "• \"I try to avoid stress and push people away, which I regret because it makes it hard to form connections.\" (Adjusted Contribution: 3.07)\n",
      "• \"I don’t have a close relationship with my family; we don’t talk much, and I often feel isolated.\" (Adjusted Contribution: 3.54)\n",
      "• \"Sometimes I struggle to sleep, and racing thoughts or stress keep me up, but I try to manage it with music and relaxation.\" (Adjusted Contribution: 3.47)\n",
      "• \"I regret how my life turned out and wish I had more stability, but I’m proud of being self-taught and consider myself a genius at figuring things out.\" (Adjusted Contribution: 2.83)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nltk\n",
    "from setfit import SetFitModel\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download NLTK dependencies\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the fine-tuned SetFit model\n",
    "model = SetFitModel.from_pretrained(\"C:\\\\Users\\\\Prathima\\\\Desktop\\\\5th_sem_project\\\\finetuned_model\")  # Replace with your model path\n",
    "\n",
    "# Tokenize text into sentences\n",
    "def split_into_sentences(text):\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "def classify_and_explain(text):\n",
    "    predicted_label = model.predict([text])[0].item()\n",
    "    label_to_class = {0: \"not depressed\", 1: \"depressed\"}\n",
    "    class_name = label_to_class[predicted_label]\n",
    "    sentences = split_into_sentences(text)\n",
    "    sentence_embeddings = torch.tensor(model.encode(sentences), dtype=torch.float32)\n",
    "    raw_scores = torch.matmul(sentence_embeddings, torch.ones(sentence_embeddings.size(-1), 1)).squeeze(-1)\n",
    "    print(len(sentences))\n",
    "    print(len(raw_scores))\n",
    "    print(sentences)\n",
    "    print(raw_scores)\n",
    "    # Get sentiment scores (neg, neu, pos, compound)\n",
    "    sentiment_scores = [sia.polarity_scores(sentence) for sentence in sentences]\n",
    "    \n",
    "    adjusted_scores = []\n",
    "    \n",
    "    for i, (raw_score, sentiment_score) in enumerate(zip(raw_scores, sentiment_scores)):\n",
    "        if predicted_label == 1:  # Depressed classification\n",
    "            # Use 'neg' score if it's significant\n",
    "            sentiment_value = sentiment_score['neg']\n",
    "            \n",
    "            # If 'neg' is not significant, use 'compound' for negative sentiment\n",
    "            if sentiment_value > 0:\n",
    "                adjusted_scores.append(raw_score + sentiment_value)\n",
    "            elif sentiment_score['compound'] < 0:  # Compound negative score\n",
    "                adjusted_scores.append(raw_score + sentiment_score['compound'])\n",
    "            else:\n",
    "                adjusted_scores.append(0)  # Ignore if neither 'neg' nor 'compound' is negative\n",
    "        elif predicted_label == 0:  # Not depressed classification\n",
    "            # Use 'pos' score for not depressed classification\n",
    "            sentiment_value = sentiment_score['pos']\n",
    "            if sentiment_value > 0:  # Only adjust if 'pos' is significant\n",
    "                adjusted_scores.append(raw_score + sentiment_value)\n",
    "            else:\n",
    "                adjusted_scores.append(0)  # Ignore sentences with low 'pos' score\n",
    "\n",
    "    # Filter sentences with non-zero adjusted scores for the explanation\n",
    "    filtered_sentences = [\n",
    "        (sentence, score) for sentence, score in zip(sentences, adjusted_scores) if score > 0\n",
    "    ]\n",
    "\n",
    "    # Generate explanation text with only relevant sentences\n",
    "    explanation = f\"The input text was classified as **{class_name}**.\\n\"\n",
    "    explanation += \"Here are the sentences with their contribution scores:\\n\\n\"\n",
    "\n",
    "    for sentence, score in filtered_sentences:\n",
    "        explanation += f\"• \\\"{sentence}\\\" (Adjusted Contribution: {score:.2f})\\n\"\n",
    "\n",
    "    # Fallback message if no sentences matched the criteria\n",
    "    if not filtered_sentences:\n",
    "        explanation += \"No sentences matched the contribution criteria for this classification.\"\n",
    "\n",
    "    return class_name, explanation\n",
    "\n",
    "#text = \"Thank you. I'm doing good. I'm from Los Angeles. Oh, great, I live in West Los Angeles, the west side. It's alright. No, I live alone, and I love it. I grew up here, so it's natural. The weather is always good; it's never bad. There's always something to do, rarely a dull moment. The traffic is horrible, but probably that's the case in almost any major city. I hate the traffic.I have enough going on here, so if I travel, it's usually within driving distance. I studied business. I've been done for a few years, so I haven't gone to school for a while. One of these days, I’ll go back to graduate school. My dream job would be working for myself and making lots of money. I don’t really have a specific dream job, just something where I can work on my terms, get paid decently, and be in a creative environment. It’s just a matter of finding the right situation.Right now, people are a little conservative about what they want, so it's tougher than it seems. But when the situation is right, I don’t think it’s too difficult. I work as an administrative assistant through a temp agency, doing desk jobs. I feel like I could do more, but for now, it works.I’m pretty close with my family. They’re around. What gets me really mad is stupid people who do things just to annoy me. They provoke me for no reason. They think it’s funny to push my buttons, like poking a stick at an angry dog. I try not to remember those situations; I just let it go and move on.To relax, I like to run, go to the gym, and listen to music. I have musician friends, so I’m usually around them. I enjoy anything related to art and creativity. Friends in general have been a positive influence. In a city like Los Angeles, where everyone is busy chasing their own goals, it’s hard to find someone uplifting. But I’ve had people point out things I could do differently, and I appreciate that.I think I can do better at handling stress and not letting people provoke me. Lately, I’ve been better at it, probably because my situation has improved. Looking back, I don’t have any major regrets. Maybe I could’ve traveled more or worked towards a better-paying job, but everyone has those thoughts at some point. I could’ve become a banker or lawyer and made more money, but I don’t like law or medicine, so it wasn’t meant to be.In life, I realized there are more things I dislike than like. I narrowed it down to what I’m good at, who I work well with, and what makes sense for me. It was a reality check, but it was necessary. Trying to conform to things that don’t suit you doesn’t make sense. It’s like trying to fit a round peg into a square hole.Memorable experiences? I don’t have any specific ones. Every day feels like a memorable experience, whether positive or negative. The fact that I have a job and can take care of myself is an accomplishment. To some, it might sound small, but for me, it’s something. I’ve gotten this far without self-destructing, and I see that as an achievement.When was the last time I felt really happy? I don’t have real highs or lows. I’m usually level. If I accomplish one thing each day, I feel happy. Yesterday, I felt happy because I accomplished something. I don’t have a best friend, but friends would probably describe me as outgoing, determined, and always networking. That’s what they would say about me.\"\n",
    "text =\"Yes, I’m doing fine. I’m originally from Indiana, but I moved to LA about ten years ago because I don’t like the cold weather—LA has great weather, the ocean, and lots to do. One of my favorite memories was spending a day on the Catalina Islands for my birthday. I’ve had a lot of changes in my life, like leaving Indiana for good, which felt huge at the time. I’ve been pursuing a career in filmmaking, something I haven’t done yet but really want to, although I can be shy and have trouble trusting people because of my past. When I’m stressed, I watch TV or go to the movies, and I don’t really argue or lose my temper. I try to avoid stress and push people away, which I regret because it makes it hard to form connections. I don’t have a close relationship with my family; we don’t talk much, and I often feel isolated. Sometimes I struggle to sleep, and racing thoughts or stress keep me up, but I try to manage it with music and relaxation. I’ve been feeling down lately, wishing my life had turned out differently, especially when it comes to having friends or a real relationship. I find comfort in playing online games with avatars where people don’t know who I am. My ideal weekend is playing games, going to the movies, or driving somewhere new to explore. If I could go back in time, I’d tell myself to keep a journal and make different choices. I regret how my life turned out and wish I had more stability, but I’m proud of being self-taught and consider myself a genius at figuring things out. Thanks for listening, and have a good day.\"\n",
    "class_name, explanation = classify_and_explain(text)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
